{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-20T12:18:59.568560Z",
     "iopub.status.busy": "2025-07-20T12:18:59.568294Z",
     "iopub.status.idle": "2025-07-20T12:19:03.094992Z",
     "shell.execute_reply": "2025-07-20T12:19:03.093984Z",
     "shell.execute_reply.started": "2025-07-20T12:18:59.568538Z"
    },
    "id": "-bAXDu4TnLHw",
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.7.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.52.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=1.0.0->bert-score) (75.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.33.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.2.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.6.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch==2.6.0 torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth==2025.6.2\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install keybert\n",
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:44:30.530668Z",
     "iopub.status.busy": "2025-07-20T08:44:30.529920Z",
     "iopub.status.idle": "2025-07-20T08:45:04.941973Z",
     "shell.execute_reply": "2025-07-20T08:45:04.941189Z",
     "shell.execute_reply.started": "2025-07-20T08:44:30.530637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 08:44:39.897472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753001080.097893     148 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753001080.153740     148 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:45:04.949711Z",
     "iopub.status.busy": "2025-07-20T08:45:04.949131Z",
     "iopub.status.idle": "2025-07-20T08:45:04.976279Z",
     "shell.execute_reply": "2025-07-20T08:45:04.975398Z",
     "shell.execute_reply.started": "2025-07-20T08:45:04.949684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TORCHINDUCTOR_DISABLE_AUTOTUNE\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:46:52.710002Z",
     "iopub.status.busy": "2025-07-20T12:46:52.709738Z",
     "iopub.status.idle": "2025-07-20T12:46:52.713648Z",
     "shell.execute_reply": "2025-07-20T12:46:52.712980Z",
     "shell.execute_reply.started": "2025-07-20T12:46:52.709982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:46:57.325675Z",
     "iopub.status.busy": "2025-07-20T12:46:57.325405Z",
     "iopub.status.idle": "2025-07-20T12:46:57.495867Z",
     "shell.execute_reply": "2025-07-20T12:46:57.495243Z",
     "shell.execute_reply.started": "2025-07-20T12:46:57.325653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>Austin &amp; Youngswick bunionectomy with Biopro ...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Youngswick Bunionectomy</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES:,1.  Hallux rigidus, le...</td>\n",
       "      <td>surgery, hallux rigidus, metatarsal, youngswic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>This patient has undergone cataract surgery, ...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>YAG Laser Capsulotomy - 1</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Secondary capsular m...</td>\n",
       "      <td>surgery, abraham capsulotomy, yag, yag laser c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>Youngswick osteotomy with internal screw fixa...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Youngswick Osteotomy</td>\n",
       "      <td>TITLE OF OPERATION: , Youngswick osteotomy wit...</td>\n",
       "      <td>surgery, hallux limitus deformity, metatarsoph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>Wound debridement with removal of Surgisis xe...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Wound Debridement</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES,1.  Open wound from rig...</td>\n",
       "      <td>surgery, open wound, prosthetic vascular graft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>Visually significant posterior capsule opacit...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>YAG Laser Capsulotomy</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Visually significant...</td>\n",
       "      <td>surgery, capsule opacity, yag, ophthalmic, yag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                        description  \\\n",
       "174         174   Austin & Youngswick bunionectomy with Biopro ...   \n",
       "177         177   This patient has undergone cataract surgery, ...   \n",
       "179         179   Youngswick osteotomy with internal screw fixa...   \n",
       "181         181   Wound debridement with removal of Surgisis xe...   \n",
       "182         182   Visually significant posterior capsule opacit...   \n",
       "\n",
       "    medical_specialty                  sample_name  \\\n",
       "174           Surgery     Youngswick Bunionectomy    \n",
       "177           Surgery   YAG Laser Capsulotomy - 1    \n",
       "179           Surgery        Youngswick Osteotomy    \n",
       "181           Surgery           Wound Debridement    \n",
       "182           Surgery       YAG Laser Capsulotomy    \n",
       "\n",
       "                                         transcription  \\\n",
       "174  PREOPERATIVE DIAGNOSES:,1.  Hallux rigidus, le...   \n",
       "177  PREOPERATIVE DIAGNOSIS: , Secondary capsular m...   \n",
       "179  TITLE OF OPERATION: , Youngswick osteotomy wit...   \n",
       "181  PREOPERATIVE DIAGNOSES,1.  Open wound from rig...   \n",
       "182  PREOPERATIVE DIAGNOSIS:,  Visually significant...   \n",
       "\n",
       "                                              keywords  \n",
       "174  surgery, hallux rigidus, metatarsal, youngswic...  \n",
       "177  surgery, abraham capsulotomy, yag, yag laser c...  \n",
       "179  surgery, hallux limitus deformity, metatarsoph...  \n",
       "181  surgery, open wound, prosthetic vascular graft...  \n",
       "182  surgery, capsule opacity, yag, ophthalmic, yag...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/medicaltranscriptions/mtsamples.csv\")\n",
    "df = df[df['medical_specialty'].isin([' Surgery',' Orthopedic',' Consult - History and Phy.'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:46:58.350575Z",
     "iopub.status.busy": "2025-07-20T12:46:58.350300Z",
     "iopub.status.idle": "2025-07-20T12:46:58.360720Z",
     "shell.execute_reply": "2025-07-20T12:46:58.359778Z",
     "shell.execute_reply.started": "2025-07-20T12:46:58.350554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1974 entries, 174 to 4602\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         1974 non-null   int64 \n",
      " 1   description        1974 non-null   object\n",
      " 2   medical_specialty  1974 non-null   object\n",
      " 3   sample_name        1974 non-null   object\n",
      " 4   transcription      1959 non-null   object\n",
      " 5   keywords           1573 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 108.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:46:58.496870Z",
     "iopub.status.busy": "2025-07-20T12:46:58.496683Z",
     "iopub.status.idle": "2025-07-20T12:46:58.502839Z",
     "shell.execute_reply": "2025-07-20T12:46:58.502324Z",
     "shell.execute_reply.started": "2025-07-20T12:46:58.496856Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "description            0\n",
       "medical_specialty      0\n",
       "sample_name            0\n",
       "transcription         15\n",
       "keywords             401\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:46:58.612310Z",
     "iopub.status.busy": "2025-07-20T12:46:58.612016Z",
     "iopub.status.idle": "2025-07-20T12:46:58.621254Z",
     "shell.execute_reply": "2025-07-20T12:46:58.620692Z",
     "shell.execute_reply.started": "2025-07-20T12:46:58.612283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total duplicated row : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'total duplicated row : {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:18:09.554548Z",
     "iopub.status.busy": "2025-07-20T12:18:09.553950Z",
     "iopub.status.idle": "2025-07-20T12:18:09.763560Z",
     "shell.execute_reply": "2025-07-20T12:18:09.762589Z",
     "shell.execute_reply.started": "2025-07-20T12:18:09.554526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "counts = df['medical_specialty'].value_counts()[:10]\n",
    "\n",
    "colors = ['orange' if i == 0 else 'skyblue' for i in range(len(counts))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(counts.index, counts.values, color=colors)\n",
    "\n",
    "# Add count labels\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_width() + 5, bar.get_y() + bar.get_height()/2,\n",
    "             str(int(bar.get_width())), va='center')\n",
    "\n",
    "plt.title('Top 10 Medical Specialty Transcription')\n",
    "plt.xlabel('Count')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:47:07.206718Z",
     "iopub.status.busy": "2025-07-20T12:47:07.206137Z",
     "iopub.status.idle": "2025-07-20T12:47:07.754862Z",
     "shell.execute_reply": "2025-07-20T12:47:07.754260Z",
     "shell.execute_reply.started": "2025-07-20T12:47:07.206695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "def clean_transcription(text):\n",
    "    text = text.strip()  # Remove leading/trailing whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove excess spaces and newlines\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "    text = re.sub(r\"([.,!?;])\", r\" \\1 \", text)  # Space around punctuation\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)  # Remove multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "df['transcription'] = df['transcription'].apply(lambda x : clean_transcription(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:47:13.871350Z",
     "iopub.status.busy": "2025-07-20T12:47:13.870672Z",
     "iopub.status.idle": "2025-07-20T12:47:13.977470Z",
     "shell.execute_reply": "2025-07-20T12:47:13.976937Z",
     "shell.execute_reply.started": "2025-07-20T12:47:13.871329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['sentence_words_count'] = df['transcription'].str.split().str.len()\n",
    "df['description_words_count'] = df['description'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:47:15.484615Z",
     "iopub.status.busy": "2025-07-20T12:47:15.483842Z",
     "iopub.status.idle": "2025-07-20T12:47:16.077064Z",
     "shell.execute_reply": "2025-07-20T12:47:16.076032Z",
     "shell.execute_reply.started": "2025-07-20T12:47:15.484590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8A0lEQVR4nOzdeVyU5f7/8fcgMOACiCBLiaC5oLmbhppLWkhmWtbJ0jI1rY5LaplxylxaKNs8lml2TmqldVqtrCxzLSNzydzQ1FBMBUMFZEQEuX5/9GO+TeAGwwzL6/l43I+4r43Pfd80c/mZe67bYowxAgAAAAAAAFzIw90BAAAAAAAAoOohKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBaDCW7BggSwWi/bv3+/Ucbt3767u3bs7dcyKbP/+/bJYLFqwYIG7QwEAABdp6tSpslgsTh83MjJS99xzj9PHrahWr14ti8Wi1atXuzsUoEIhKQVUMhaL5aI23jD/tHPnTk2dOtXpCa2S+umnn2SxWPTyyy8XqevXr58sFovmz59fpK5r16667LLLXBEiAABVSuGHX4Wbj4+PwsPDFRsbq1mzZunkyZPuDrHM/PDDD5o6daoyMjLcHYok6f3335fFYtEnn3xSpK5Vq1ayWCxatWpVkbqIiAh16tTJFSECuEQkpYBK5u2333bYrrvuumLLo6Oj3Ryp89x1113KyclR/fr1L7nvzp07NW3atGKTUt98842++eYbJ0R48dq2bavq1avr+++/L1L3ww8/yNPTU+vWrXMoP3PmjDZs2KDOnTu7KkwAAKqc6dOn6+2339acOXM0ZswYSdK4cePUokULbd261c3Rndvjjz+unJycEvX94YcfNG3atGKTUrt379Ybb7xRyuguTZcuXSSpyDwpKytL27dvL3aedPDgQR08eNDeF0D54unuAAA41+DBgx32f/zxRy1fvrxI+d+dOnVK1atXL8vQnM5ms6lGjRqqVq2aqlWr5vTxvb29nT7mhXh6eqpjx45FJlS7d+9Wenq67rzzziITsU2bNun06dNOmWxVxL8DAABcIS4uTu3bt7fvx8fHa+XKlbrxxht10003KSkpSb6+vm6M0FHhPMnT01Oens7/Z5/VanX6mBcSHh6uqKioInOhxMREGWN02223Fakr3C/tPMkYo9OnT5erawxUBtwpBVRB3bt315VXXqlNmzapa9euql69uv71r39Jkj799FP16dNH4eHhslqtatiwoZ588kmdPXu22DF27typHj16qHr16rrssss0Y8aMIr/vlVdeUfPmzVW9enXVrl1b7du31+LFix3aHDp0SMOHD7f/3qioKD3wwAM6c+aMpP+7dX7NmjX65z//qbp16+ryyy93qPvr3U6RkZG68cYb9c0336h169by8fFRs2bN9PHHH9vbLFiwQLfddpskqUePHkW+2ljcmlJHjx7V8OHDFRISIh8fH7Vq1UoLFy50aFO49tILL7ygefPmqWHDhrJarbrqqqu0YcOGC16fLl26KC0tTXv37rWXrVu3Tn5+fho5cqQ9QfXXusJ+hV577TU1b95cVqtV4eHhGjVqVJFPOc/3d5CRkaF77rlH/v7+CggI0JAhQ4r9lDQ1NVVDhw7V5ZdfLqvVqrCwMPXr16/cfB0SAICydO2112ry5Mk6cOCA3nnnHYe6Xbt26dZbb1VgYKB8fHzUvn17ffbZZw5t8vLyNG3aNDVq1Eg+Pj6qU6eOunTpouXLlxcZ6x//+IeCg4Pl6+urJk2a6LHHHrPXF64btXPnTt15552qXbu2fV5Q3JpSFotFo0eP1qJFi9SkSRP5+PioXbt2Wrt2rcOYEydOlCRFRUXZ50mF7/HFrSn122+/6bbbblNgYKCqV6+uq6++Wl988YVDm8K1l95//309/fTTuvzyy+Xj46OePXs6zH3OpUuXLvr5558d7v5at26dmjdvrri4OP34448qKChwqLNYLPY7yvPz8/Xkk0/a52eRkZH617/+pdzcXIffUziX/Prrr9W+fXv5+vrq9ddflyT9/vvv6t+/v2rUqKG6detq/PjxRfpL0p49ezRgwACFhobKx8dHl19+uQYOHKjMzMwLHidQVXCnFFBFHTt2THFxcRo4cKAGDx6skJAQSX8mamrWrKkJEyaoZs2aWrlypZ544gllZWXp+eefdxjjxIkT6t27t2655Rb94x//0IcffqhJkyapRYsWiouLkyS98cYbGjt2rG699VY9+OCDOn36tLZu3ar169frzjvvlCQdPnxYHTp0UEZGhkaOHKmmTZvq0KFD+vDDD3Xq1CmHO5b++c9/Kjg4WE888YRsNtt5j3HPnj26/fbbdf/992vIkCGaP3++brvtNi1btkzXXXedunbtqrFjx2rWrFn617/+Zf9K47m+2piTk6Pu3btr7969Gj16tKKiovTBBx/onnvuUUZGhh588EGH9osXL9bJkyd13333yWKxaMaMGbrlllv022+/ycvL65xx//XW9CuuuELSnxOqq6++Wh07dpSXl5d++OEH3XTTTfa6WrVqqVWrVpL+nEROmzZNvXr10gMPPKDdu3drzpw52rBhg9atW+fwu4v7OzDGqF+/fvr+++91//33Kzo6Wp988omGDBlSJNYBAwZox44dGjNmjCIjI3X06FEtX75cKSkpioyMPO/1AQCgMrjrrrv0r3/9S998841GjBghSdqxY4c6d+6syy67TI8++qhq1Kih999/X/3799dHH32km2++WdKf79kJCQm699571aFDB2VlZWnjxo3avHmzfQmGrVu36pprrpGXl5dGjhypyMhI7du3T59//rmefvpph1huu+02NWrUSM8884yMMeeNe82aNfrf//6nsWPHymq16rXXXlPv3r31008/6corr9Qtt9yiX3/9Ve+++65efvllBQUFSZKCg4OLHS8tLU2dOnXSqVOnNHbsWNWpU0cLFy7UTTfdpA8//NB+zIWeffZZeXh46OGHH1ZmZqZmzJihQYMGaf369eeNu0uXLnr77be1fv16+4eH69atU6dOndSpUydlZmZq+/btatmypb2uadOmqlOnjiTp3nvv1cKFC3XrrbfqoYce0vr165WQkKCkpKQia1Xt3r1bd9xxh+677z6NGDFCTZo0UU5Ojnr27KmUlBSNHTtW4eHhevvtt7Vy5UqHvmfOnFFsbKxyc3M1ZswYhYaG6tChQ1q6dKkyMjLk7+9/3uMEqgwDoFIbNWqU+fv/6t26dTOSzNy5c4u0P3XqVJGy++67z1SvXt2cPn26yBhvvfWWvSw3N9eEhoaaAQMG2Mv69etnmjdvft4Y7777buPh4WE2bNhQpK6goMAYY8z8+fONJNOlSxeTn5/v0KawLjk52V5Wv359I8l89NFH9rLMzEwTFhZm2rRpYy/74IMPjCSzatWqIr+7W7duplu3bvb9mTNnGknmnXfesZedOXPGxMTEmJo1a5qsrCxjjDHJyclGkqlTp445fvy4ve2nn35qJJnPP//8vOcjKyvLVKtWzQwfPtxe1qRJEzNt2jRjjDEdOnQwEydOtNcFBweb6667zhhjzNGjR423t7e5/vrrzdmzZ+1tXn31VSPJvPnmmw7HV9zfwZIlS4wkM2PGDHtZfn6+ueaaa4wkM3/+fGOMMSdOnDCSzPPPP3/e4wEAoCIrnGcUN08p5O/v7zC/6Nmzp2nRooXD3KmgoMB06tTJNGrUyF7WqlUr06dPn/P+/q5du5patWqZAwcOOJQXzpGMMWbKlClGkrnjjjuK9C+s+ytJRpLZuHGjvezAgQPGx8fH3Hzzzfay559/vsgcq1D9+vXNkCFD7Pvjxo0zksx3331nLzt58qSJiooykZGR9nnJqlWrjCQTHR1tcnNz7W3//e9/G0lm27Zt5z0fO3bsMJLMk08+aYwxJi8vz9SoUcMsXLjQGGNMSEiImT17tjHm/+ZUI0aMMMYYs2XLFiPJ3HvvvQ5jPvzww0aSWblypcPxSTLLli1zaFs4H3z//fftZTabzVxxxRUOc8qff/7ZSDIffPDBeY8HqOr4+h5QRVmtVg0dOrRI+V+/J3/y5Emlp6frmmuu0alTp7Rr1y6HtjVr1nRYq8rb21sdOnTQb7/9Zi8LCAjQ77//fs6vrRUUFGjJkiXq27evwzoNhf5+u/mIESMuev2o8PBwh0/l/Pz8dPfdd+vnn39WamrqRY3xV19++aVCQ0N1xx132Mu8vLw0duxYZWdna82aNQ7tb7/9dtWuXdu+f80110iSw/kpTq1atdSyZUv7Ggjp6enavXu3/akxnTt3tn9l79dff9Uff/xhv7vq22+/1ZkzZzRu3Dh5ePzfS/yIESPk5+dX5Bb64v4OvvzyS3l6euqBBx6wl1WrVs2+qGshX19feXt7a/Xq1Tpx4sR5jwkAgMqsZs2a9qfwHT9+XCtXrtQ//vEP+1wqPT1dx44dU2xsrPbs2aNDhw5J+nOetGPHDu3Zs6fYcf/44w+tXbtWw4YNU0REhEPd3+dIknT//fdfdMwxMTFq166dfT8iIkL9+vXT119/XWTZhovx5ZdfqkOHDg7LCdSsWVMjR47U/v37tXPnTof2Q4cOdbgb/mLnSdHR0apTp459nvTLL7/IZrPZ50mdOnWyz5MSExN19uxZe0xffvmlJGnChAkOYz700EOSVGSeFBUVpdjY2CLHGRYWpltvvdVeVr16dY0cOdKhXeGdUF9//bVOnTp13mMCqjKSUkAVddlllxW7kPeOHTt08803y9/fX35+fgoODrYnnv7+/ffLL7+8yISodu3aDgmKSZMmqWbNmurQoYMaNWqkUaNGOSzi/ccffygrK0tXXnnlRcUdFRV10cd4xRVXFImvcePGklSiNY8OHDigRo0aOSR7pP/7ut+BAwccyv8+eSxMUF1MAqdLly72taN++OEHVatWTVdffbWkPydbmzZtUm5ubpH1pApjaNKkicN43t7eatCgQZEYi/s7OHDggMLCwlSzZk2H8r+PabVa9dxzz+mrr75SSEiIunbtqhkzZpQo4QcAQEWWnZ2tWrVqSZL27t0rY4wmT56s4OBgh23KlCmS/lyjUvrziX4ZGRlq3LixWrRooYkTJzo8ya8wQVMW86RGjRoVKWvcuLFOnTqlP/7446LHKXTgwIEicwXJ+fMki8WiTp062deOWrdunerWrWtf8uCvSani5kkeHh72toVCQ0MVEBBQJMbizueBAweKnWP+/dijoqI0YcIE/ec//1FQUJBiY2M1e/Zs1pMC/oakFFBFFffkkIyMDHXr1k2//PKLpk+frs8//1zLly/Xc889J0kOi0ZKOucdS+YvaxhER0dr9+7deu+999SlSxd99NFH6tKli31S5oy4y6uLOT/nUjh5WrdundatW6cWLVrYk0SdOnVSbm6uNmzYoO+//16enp72hNWlKu35HDdunH799VclJCTIx8dHkydPVnR0tH7++edSjQsAQEXx+++/KzMz057oKJwvPfzww1q+fHmxW2Hbrl27at++fXrzzTd15ZVX6j//+Y/atm2r//znPyWKpSrNkzIzM7Vt2zb7elKFOnXqpAMHDujQoUP6/vvvFR4ergYNGjj0L+4us+KU9ny++OKL2rp1q/71r38pJydHY8eOVfPmzfX777+XalygMiEpBcBu9erVOnbsmBYsWKAHH3xQN954o3r16uXwFbSSqFGjhm6//XbNnz9fKSkp6tOnj55++mmdPn1awcHB8vPz0/bt2510FP+n8JPKv/r1118lyb4I98VOSiSpfv362rNnT5HkXOHXGuvXr1+KaB39dbHzdevW2Z8YI/35tcT69evbE1Zt2rRR9erVHWLYvXu3w3hnzpxRcnLyRcVYv359HTlyRNnZ2Q7lfx+zUMOGDfXQQw/pm2++0fbt23XmzBm9+OKLF3+wAABUYG+//bYk2b/mVZgA8fLyUq9evYrdCu+qkqTAwEANHTpU7777rg4ePKiWLVtq6tSpDmOVxTypuK8M/vrrr6pevbp9MfNLnScVN1dw9TypXbt2slqtWr16tdavX+9QV79+fRUUFBQ59rS0NGVkZFz0PGnfvn1F5pjnmie1aNFCjz/+uNauXavvvvtOhw4d0ty5cy/6WIHKjqQUALvCT6z++iZ75swZvfbaayUe89ixYw773t7eatasmYwxysvLk4eHh/r376/PP/9cGzduLNL/Yj4tO5fDhw87PEUlKytLb731llq3bq3Q0FBJfybMpD/vEruQG264Qampqfrf//5nL8vPz9crr7yimjVrqlu3biWO9e/Cw8MVFRWlFStWaOPGjQ6fAEp/fgq4ZMkS7d6922Hthl69esnb21uzZs1yOHf//e9/lZmZqT59+lzwd99www3Kz8/XnDlz7GVnz57VK6+84tDu1KlTOn36tENZw4YNVatWrWIfiwwAQGWzcuVKPfnkk4qKitKgQYMkSXXr1lX37t31+uuv68iRI0X6/PWrcX+fJ9WsWVNXXHGF/X00ODhYXbt21ZtvvqmUlBSHtqWZI0l/rre0efNm+/7Bgwf16aef6vrrr7fPCS91nvTTTz8pMTHRXmaz2TRv3jxFRkaqWbNmpYr3r9q3by8fHx8tWrRIhw4dcpgnWa1WtW3bVrNnz5bNZnOYJ91www2SpJkzZzqM99JLL0nSRc+TDh8+rA8//NBedurUKc2bN8+hXVZWlvLz8x3KWrRoIQ8PD+ZJwF94ujsAAOVHp06dVLt2bQ0ZMkRjx46VxWLR22+/XapJz/XXX6/Q0FB17txZISEhSkpK0quvvqo+ffrYPyV85pln9M0336hbt24aOXKkoqOjdeTIEX3wwQf6/vvvFRAQUKLf3bhxYw0fPlwbNmxQSEiI3nzzTaWlpWn+/Pn2Nq1bt1a1atX03HPPKTMzU1arVddee63q1q1bZLyRI0fq9ddf1z333KNNmzYpMjJSH374odatW6eZM2c6fOrpDIWPPJbk8Cmf9Oe1evfdd+3tCgUHBys+Pl7Tpk1T7969ddNNN2n37t167bXXdNVVVzksTH8uffv2VefOnfXoo49q//79atasmT7++OMiayD8+uuv6tmzp/7xj3+oWbNm8vT01CeffKK0tDQNHDiwtIcPAEC58tVXX2nXrl3Kz89XWlqaVq5cqeXLl6t+/fr67LPP5OPjY287e/ZsdenSRS1atNCIESPUoEEDpaWlKTExUb///rt++eUXSVKzZs3UvXt3tWvXToGBgdq4caM+/PBDjR492j7WrFmz1KVLF7Vt21YjR45UVFSU9u/fry+++EJbtmwp8fFceeWVio2N1dixY2W1Wu0fQk6bNs3epnAh9Mcee0wDBw6Ul5eX+vbta09W/dWjjz6qd999V3FxcRo7dqwCAwO1cOFCJScn66OPPiqyJmdpeHt766qrrtJ3330nq9XqsGC79Oc8qfCu7b/Ok1q1aqUhQ4Zo3rx59mUrfvrpJy1cuFD9+/dXjx49Lvi7R4wYoVdffVV33323Nm3apLCwML399tv2u9YLrVy5UqNHj9Ztt92mxo0bKz8/X2+//baqVaumAQMGOOEsAJWEex76B8BVRo0aVeQxwN26dTPNmzcvtv26devM1VdfbXx9fU14eLh55JFHzNdff+3wiNvzjTFkyBBTv359+/7rr79uunbtaurUqWOsVqtp2LChmThxosnMzHTod+DAAXP33Xeb4OBgY7VaTYMGDcyoUaPsjwo+3+OYC+v++rji+vXrmz59+pivv/7atGzZ0litVtO0adNiH8v7xhtvmAYNGphq1ao5HGe3bt1Mt27dHNqmpaWZoUOHmqCgIOPt7W1atGhh5s+f79AmOTnZSDLPP/98kd8lyUyZMqVIeXFef/11I8lcdtllReo2b95sf5xzWlpakfpXX33VNG3a1Hh5eZmQkBDzwAMPmBMnTji0Od/fwbFjx8xdd91l/Pz8jL+/v7nrrrvsjzYuPN709HQzatQo07RpU1OjRg3j7+9vOnbs6PCIZAAAKrrCeUbh5u3tbUJDQ811111n/v3vf5usrKxi++3bt8/cfffdJjQ01Hh5eZnLLrvM3HjjjebDDz+0t3nqqadMhw4dTEBAgPH19TVNmzY1Tz/9tDlz5ozDWNu3bzc333yzCQgIMD4+PqZJkyZm8uTJ9vopU6YYSeaPP/4oEkdh3V9JMqNGjTLvvPOOadSokbFaraZNmzYOc71CTz75pLnsssuMh4eHw3yrfv36ZsiQIUWO+dZbb7XH2aFDB7N06VKHNqtWrTKSiszJCudPf59XnUt8fLyRZDp16lSk7uOPPzaSTK1atUx+fr5DXV5enpk2bZqJiooyXl5epl69eiY+Pt6cPn3aoV3hXLI4Bw4cMDfddJOpXr26CQoKMg8++KBZtmyZwzzyt99+M8OGDTMNGzY0Pj4+JjAw0PTo0cN8++23F3V8QFVhMaaU930CQDkUGRmpK6+8UkuXLnV3KAAAAOWKxWLRqFGj9Oqrr7o7FABVHGtKAQAAAAAAwOVISgEAAAAAAMDlSEoBAAAAAADA5VhTCgAAAAAAAC7HnVIAAAAAAABwOZJSAAAAAAAAcDlPdwdQHhQUFOjw4cOqVauWLBaLu8MBAADliDFGJ0+eVHh4uDw8+DyvEPMnAABwLhc7fyIpJenw4cOqV6+eu8MAAADl2MGDB3X55Ze7O4xyg/kTAAC4kAvNn0hKSapVq5akP0+Wn5+fm6MBAADlSVZWlurVq2efL+BPzJ8AAMC5XOz8iaSUZL/l3M/Pj0kVAAAoFl9Rc8T8CQAAXMiF5k8sjAAAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACX83R3AKh8MjMzZbPZStS3Ro0a8vf3d3JEAABUHgkJCfr444+1a9cu+fr6qlOnTnruuefUpEkTe5vTp0/roYce0nvvvafc3FzFxsbqtddeU0hIiL1NSkqKHnjgAa1atUo1a9bUkCFDlJCQIE9PpoeulJKSovT0dKeMFRQUpIiICKeMBQCAKzDrgFNlZmYqMqqBMk4cL1H/gNqB2p/8G4kpAADOYc2aNRo1apSuuuoq5efn61//+peuv/567dy5UzVq1JAkjR8/Xl988YU++OAD+fv7a/To0brlllu0bt06SdLZs2fVp08fhYaG6ocfftCRI0d09913y8vLS88884w7D69KSUlJUdOm0crJOeWU8Xx9q2vXriQSUwCACsNijDHuDsLdsrKy5O/vr8zMTPn5+bk7nArt8OHDuuyyy3TdY/Pl6xd4SX1zso5r+dNDdejQIYWHh5dRhAAAXJryPk/4448/VLduXa1Zs0Zdu3ZVZmamgoODtXjxYt16662SpF27dik6OlqJiYm6+uqr9dVXX+nGG2/U4cOH7XdPzZ07V5MmTdIff/whb2/vC/7e8n5eKoLNmzerXbt26jhsivzCIks1VtaR/Vr/5jRt2rRJbdu2dU6AAACU0MXOE7hTCmXC1y9QvgHB7g4DAIBKLzMzU5IUGPjnh0GbNm1SXl6eevXqZW/TtGlTRURE2JNSiYmJatGihcPX+WJjY/XAAw9ox44datOmTZHfk5ubq9zcXPt+VlZWWR1SleMXFqnAiCYXbggAQCXDQucAAAAVVEFBgcaNG6fOnTvryiuvlCSlpqbK29tbAQEBDm1DQkKUmppqb/PXhFRhfWFdcRISEuTv72/f6tWr5+SjAQAAVQ1JKQAAgApq1KhR2r59u957770y/13x8fHKzMy0bwcPHizz3wkAACo3vr4HAABQAY0ePVpLly7V2rVrdfnll9vLQ0NDdebMGWVkZDjcLZWWlqbQ0FB7m59++slhvLS0NHtdcaxWq6xWq5OPAgAAVGXcKQUAAFCBGGM0evRoffLJJ1q5cqWioqIc6tu1aycvLy+tWLHCXrZ7926lpKQoJiZGkhQTE6Nt27bp6NGj9jbLly+Xn5+fmjVr5poDAQAAVR53SgEAAFQgo0aN0uLFi/Xpp5+qVq1a9jWg/P395evrK39/fw0fPlwTJkxQYGCg/Pz8NGbMGMXExOjqq6+WJF1//fVq1qyZ7rrrLs2YMUOpqal6/PHHNWrUKO6GAgAALkNSCuXOuRZYPZ8aNWrI39+/DKIBAKB8mTNnjiSpe/fuDuXz58/XPffcI0l6+eWX5eHhoQEDBig3N1exsbF67bXX7G2rVaumpUuX6oEHHlBMTIxq1KihIUOGaPr06a46DAAAAJJSKD/ycmySxUPt2rW75L4BtQO1P/k3ElMAgErPGHPBNj4+Ppo9e7Zmz559zjb169fXl19+6czQAAAALglJKZQbZ/NOS6ZAPSbOU62gkAt3+P9yso5r+dNDZbPZSEoBAAAAAFBBkJRCuWP1C5RvQLC7wwAAAAAAAGWIp+8BAAAAAADA5UhKAQAAAAAAwOVISgEAAAAAAMDlSEoBAAAAAADA5dyalFq7dq369u2r8PBwWSwWLVmypEibpKQk3XTTTfL391eNGjV01VVXKSUlxV5/+vRpjRo1SnXq1FHNmjU1YMAApaWlufAoAAAAAAAAcKncmpSy2Wxq1aqVZs+eXWz9vn371KVLFzVt2lSrV6/W1q1bNXnyZPn4+NjbjB8/Xp9//rk++OADrVmzRocPH9Ytt9ziqkMAAAAAAABACXi685fHxcUpLi7unPWPPfaYbrjhBs2YMcNe1rBhQ/vPmZmZ+u9//6vFixfr2muvlSTNnz9f0dHR+vHHH3X11VeXXfAAAAAAAAAosXK7plRBQYG++OILNW7cWLGxsapbt646duzo8BW/TZs2KS8vT7169bKXNW3aVBEREUpMTDzn2Lm5ucrKynLYAAAAAAAA4DrlNil19OhRZWdn69lnn1Xv3r31zTff6Oabb9Ytt9yiNWvWSJJSU1Pl7e2tgIAAh74hISFKTU0959gJCQny9/e3b/Xq1SvLQwEAAAAAAMDflNukVEFBgSSpX79+Gj9+vFq3bq1HH31UN954o+bOnVuqsePj45WZmWnfDh486IyQAQAAAAAAcJHcuqbU+QQFBcnT01PNmjVzKI+Ojtb3338vSQoNDdWZM2eUkZHhcLdUWlqaQkNDzzm21WqV1Wotk7gBAAAAAABwYeX2Tilvb29dddVV2r17t0P5r7/+qvr160uS2rVrJy8vL61YscJev3v3bqWkpCgmJsal8QIAAAAAAODiufVOqezsbO3du9e+n5ycrC1btigwMFARERGaOHGibr/9dnXt2lU9evTQsmXL9Pnnn2v16tWSJH9/fw0fPlwTJkxQYGCg/Pz8NGbMGMXExPDkPQAAAAAAgHLMrUmpjRs3qkePHvb9CRMmSJKGDBmiBQsW6Oabb9bcuXOVkJCgsWPHqkmTJvroo4/UpUsXe5+XX35ZHh4eGjBggHJzcxUbG6vXXnvN5ccCAAAAAACAi+fWpFT37t1ljDlvm2HDhmnYsGHnrPfx8dHs2bM1e/ZsZ4cHAAAAAACAMlJu15QCAAAAAABA5UVSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALufp7gAAd8vMzJTNZitR3xo1asjf39/JEQEAAAAAUPlxpxSqtMzMTEVGNdBll11Woi0yqoEyMzPdfRgAgCpm7dq16tu3r8LDw2WxWLRkyRKHeovFUuz2/PPP29tERkYWqX/22WddfCQAAKAq404pVGk2m00ZJ47rusfmy9cv8JL65mQd1/Knh8pms3G3FADApWw2m1q1aqVhw4bplltuKVJ/5MgRh/2vvvpKw4cP14ABAxzKp0+frhEjRtj3a9WqVTYBAwAAFIOkFCDJ1y9QvgHB7g4DAICLEhcXp7i4uHPWh4aGOux/+umn6tGjhxo0aOBQXqtWrSJtAQAAXIWkFAAAQCWWlpamL774QgsXLixS9+yzz+rJJ59URESE7rzzTo0fP16ensVPD3Nzc5Wbm2vfz8rKKrOYy7uUlBSlp6eXepykpCQnRAMAQMVFUgoAAKASW7hwoWrVqlXka35jx45V27ZtFRgYqB9++EHx8fE6cuSIXnrppWLHSUhI0LRp01wRcrmWkpKipk2jlZNzymlj5uWecdpYAABUJCSlAAAAKrE333xTgwYNko+Pj0P5hAkT7D+3bNlS3t7euu+++5SQkCCr1VpknPj4eIc+WVlZqlevXtkFXk6lp6crJ+eUOg6bIr+wyFKNdWRborZ/Nk/5+fnOCQ4AgAqGpBQAAEAl9d1332n37t363//+d8G2HTt2VH5+vvbv368mTZoUqbdarcUmq6oqv7BIBUYUPU+XIuvIfucEAwBABeXh7gAAAABQNv773/+qXbt2atWq1QXbbtmyRR4eHqpbt64LIgMAAOBOKQAAgAonOztbe/fute8nJydry5YtCgwMVEREhKQ/v173wQcf6MUXXyzSPzExUevXr1ePHj1Uq1YtJSYmavz48Ro8eLBq167tsuMAAABVG0kpAACACmbjxo3q0aOHfb9wrachQ4ZowYIFkqT33ntPxhjdcccdRfpbrVa99957mjp1qnJzcxUVFaXx48c7rBkFAABQ1khKAQAAVDDdu3eXMea8bUaOHKmRI0cWW9e2bVv9+OOPZREaAADARWNNKQAAAAAAALgcSSkAAAAAAAC4HEkpAAAAAAAAuJxbk1Jr165V3759FR4eLovFoiVLlpyz7f333y+LxaKZM2c6lB8/flyDBg2Sn5+fAgICNHz4cGVnZ5dt4AAAAAAAACgVtyalbDabWrVqpdmzZ5+33SeffKIff/xR4eHhReoGDRqkHTt2aPny5Vq6dKnWrl17zkU9AQAAAAAAUD649el7cXFxiouLO2+bQ4cOacyYMfr666/Vp08fh7qkpCQtW7ZMGzZsUPv27SVJr7zyim644Qa98MILxSaxAAAAAAAA4H7lek2pgoIC3XXXXZo4caKaN29epD4xMVEBAQH2hJQk9erVSx4eHlq/fr0rQwUAAAAAAMAlcOudUhfy3HPPydPTU2PHji22PjU1VXXr1nUo8/T0VGBgoFJTU885bm5urnJzc+37WVlZzgkYAAAAAAAAF6Xc3im1adMm/fvf/9aCBQtksVicOnZCQoL8/f3tW7169Zw6PgAAAAAAAM6v3CalvvvuOx09elQRERHy9PSUp6enDhw4oIceekiRkZGSpNDQUB09etShX35+vo4fP67Q0NBzjh0fH6/MzEz7dvDgwbI8FAAAAAAAAPxNuf363l133aVevXo5lMXGxuquu+7S0KFDJUkxMTHKyMjQpk2b1K5dO0nSypUrVVBQoI4dO55zbKvVKqvVWnbBAwAAAAAA4LzcmpTKzs7W3r177fvJycnasmWLAgMDFRERoTp16ji09/LyUmhoqJo0aSJJio6OVu/evTVixAjNnTtXeXl5Gj16tAYOHMiT90opMzNTNpvtkvudby0vAAAAAACAQm5NSm3cuFE9evSw70+YMEGSNGTIEC1YsOCixli0aJFGjx6tnj17ysPDQwMGDNCsWbPKItwqIzMzU5FRDZRx4niJx8jPL3BiRAAAAAAAoLJxa1Kqe/fuMsZcdPv9+/cXKQsMDNTixYudGBVsNpsyThzXdY/Nl69f4CX1PXFon76bNUEFBWfLKDoAAAAAAFAZlNs1peB+vn6B8g0IvqQ+p7OOlVE0AAAAAACgMim3T98DAAAAAABA5UVSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAu5+nuAAAAAACULykpKUpPT3fKWEFBQYqIiHDKWACAyoWkFAAAAAC7lJQUNW0arZycU04Zz9e3unbtSiIxBQAogqQUAAAAALv09HTl5JxSx2FT5BcWWaqxso7s1/o3pyk9PZ2kFACgCJJSAAAAAIrwC4tUYEQTd4cBAKjEWOgcAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALsdC56g0UlNTXdIHAAAAAACUHkkpVHh5OTbJ4qF27dqVeIz8/AInRgQAAAAAAC6EpBQqvLN5pyVToB4T56lWUMgl9T1xaJ++mzVBBQVnyyg6AAAAAABQHJJSqDSsfoHyDQi+pD6ns46VUTQAAAAAAOB8WOgcAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAACgglm7dq369u2r8PBwWSwWLVmyxKH+nnvukcVicdh69+7t0Ob48eMaNGiQ/Pz8FBAQoOHDhys7O9uFRwEAAKo6klIAAAAVjM1mU6tWrTR79uxztundu7eOHDli3959912H+kGDBmnHjh1avny5li5dqrVr12rkyJFlHToAAIAdT98DAACoYOLi4hQXF3feNlarVaGhocXWJSUladmyZdqwYYPat28vSXrllVd0ww036IUXXlB4eLjTYwYAAPg77pQCAACohFavXq26deuqSZMmeuCBB3Ts2DF7XWJiogICAuwJKUnq1auXPDw8tH79eneECwAAqiDulAIAAKhkevfurVtuuUVRUVHat2+f/vWvfykuLk6JiYmqVq2aUlNTVbduXYc+np6eCgwMVGpqarFj5ubmKjc3176flZVVpscAAAAqP5JSAAAAlczAgQPtP7do0UItW7ZUw4YNtXr1avXs2bNEYyYkJGjatGnOChEAAICv7wEAAFR2DRo0UFBQkPbu3StJCg0N1dGjRx3a5Ofn6/jx4+dchyo+Pl6ZmZn27eDBg2UeNwAAqNxISgEAAFRyv//+u44dO6awsDBJUkxMjDIyMrRp0yZ7m5UrV6qgoEAdO3Ysdgyr1So/Pz+HDQAAoDT4+h4AAEAFk52dbb/rSZKSk5O1ZcsWBQYGKjAwUNOmTdOAAQMUGhqqffv26ZFHHtEVV1yh2NhYSVJ0dLR69+6tESNGaO7cucrLy9Po0aM1cOBAnrwHAABchjulAAAAKpiNGzeqTZs2atOmjSRpwoQJatOmjZ544glVq1ZNW7du1U033aTGjRtr+PDhateunb777jtZrVb7GIsWLVLTpk3Vs2dP3XDDDerSpYvmzZvnrkMCAABVEHdKAQAAVDDdu3eXMeac9V9//fUFxwgMDNTixYudGRYAAMAl4U4pAAAAAAAAuBxJKQAAAAAAALicW5NSa9euVd++fRUeHi6LxaIlS5bY6/Ly8jRp0iS1aNFCNWrUUHh4uO6++24dPnzYYYzjx49r0KBB8vPzU0BAgIYPH67s7GwXHwkAAAAAAAAuhVuTUjabTa1atdLs2bOL1J06dUqbN2/W5MmTtXnzZn388cfavXu3brrpJod2gwYN0o4dO7R8+XItXbpUa9eu1ciRI111CAAAAAAAACgBty50HhcXp7i4uGLr/P39tXz5coeyV199VR06dFBKSooiIiKUlJSkZcuWacOGDWrfvr0k6ZVXXtENN9ygF154gUcaAwAAAAAAlFMVak2pzMxMWSwWBQQESJISExMVEBBgT0hJUq9eveTh4aH169efc5zc3FxlZWU5bAAAAAAAAHAdt94pdSlOnz6tSZMm6Y477pCfn58kKTU1VXXr1nVo5+npqcDAQKWmpp5zrISEBE2bNq1M4wUAAADwp6SkJKeMExQUpIiICKeMBQBwvwqRlMrLy9M//vEPGWM0Z86cUo8XHx+vCRMm2PezsrJUr169Uo8LAAAA4P/kZB6TZNHgwYOdMp6vb3Xt2pVEYgoAKolyn5QqTEgdOHBAK1eutN8lJUmhoaE6evSoQ/v8/HwdP35coaGh5xzTarXKarWWWcwAAAAApLxTJyUZtb5zkoKjmpZqrKwj+7X+zWlKT08nKQUAlUS5TkoVJqT27NmjVatWqU6dOg71MTExysjI0KZNm9SuXTtJ0sqVK1VQUKCOHTu6I2QAAAAAf1OzboQCI5q4OwwAQDnj1qRUdna29u7da99PTk7Wli1bFBgYqLCwMN16663avHmzli5dqrNnz9rXiQoMDJS3t7eio6PVu3dvjRgxQnPnzlVeXp5Gjx6tgQMH8uQ9AAAAAACAcsytSamNGzeqR48e9v3CdZ6GDBmiqVOn6rPPPpMktW7d2qHfqlWr1L17d0nSokWLNHr0aPXs2VMeHh4aMGCAZs2a5ZL4AQAAAAAAUDJuTUp1795dxphz1p+vrlBgYKAWL17szLAAAAAAAABQxjzcHQAAAAAAAACqHpJSAAAAAAAAcDmSUgAAAAAAAHA5klIAAAAAAABwOZJSAAAAAAAAcDmSUgAAAAAAAHA5klIAAAAAAABwOZJSAAAAAAAAcDmSUgAAAAAAAHA5klIAAAAAAABwOZJSAAAAAAAAcDmSUgAAAAAAAHA5klIAAAAAAABwOZJSAAAAAAAAcDmSUgAAAAAAAHA5klIAAAAAAABwOZJSAAAAAAAAcDmSUgAAAAAAAHA5klIAAAAAAABwOZJSAAAAAAAAcDlPdweAspOZmSmbzXbJ/VJTU8sgmsqrpOerRo0a8vf3d3I0AAAAAABUDCSlKqnMzExFRjVQxonjJR4jP7/AiRFVPnk5NsnioXbt2pWof0DtQO1P/o3EFAAAAACgSiIpVUnZbDZlnDiu6x6bL1+/wEvqe+LQPn03a4IKCs6WUXSVw9m805IpUI+J81QrKOSS+uZkHdfyp4fKZrORlAIAAAAAVEkkpSo5X79A+QYEX1Kf01nHyiiayslagnMMAAAAAEBVx0LnAAAAFczatWvVt29fhYeHy2KxaMmSJfa6vLw8TZo0SS1atFCNGjUUHh6uu+++W4cPH3YYIzIyUhaLxWF79tlnXXwkAACgKiMpBQAAUMHYbDa1atVKs2fPLlJ36tQpbd68WZMnT9bmzZv18ccfa/fu3brpppuKtJ0+fbqOHDli38aMGeOK8AEAACTx9T0AAIAKJy4uTnFxccXW+fv7a/ny5Q5lr776qjp06KCUlBRFRETYy2vVqqXQ0NAyjRUAAOBcSEoBAABUcpmZmbJYLAoICHAof/bZZ/Xkk08qIiJCd955p8aPHy9Pz+Knh7m5ucrNzbXvZ2VllWXIwDklJSU5ZZygoCCHJC0AwPVISgEAAFRip0+f1qRJk3THHXfIz8/PXj527Fi1bdtWgYGB+uGHHxQfH68jR47opZdeKnachIQETZs2zVVhA0XkZB6TZNHgwYOdMp6vb3Xt2pVEYgoA3IikFAAAQCWVl5enf/zjHzLGaM6cOQ51EyZMsP/csmVLeXt767777lNCQoKsVmuRseLj4x36ZGVlqV69emUXPPA3eadOSjJqfeckBUc1LdVYWUf2a/2b05Senk5SCgDciKQUAABAJVSYkDpw4IBWrlzpcJdUcTp27Kj8/Hzt379fTZo0KVJvtVqLTVYBrlazboQCI4r+jQIAKh6SUgAAAJVMYUJqz549WrVqlerUqXPBPlu2bJGHh4fq1q3rgggBAABISgEAAFQ42dnZ2rt3r30/OTlZW7ZsUWBgoMLCwnTrrbdq8+bNWrp0qc6ePavU1FRJUmBgoLy9vZWYmKj169erR48eqlWrlhITEzV+/HgNHjxYtWvXdtdhAQCAKoakFAAAQAWzceNG9ejRw75fuNbTkCFDNHXqVH322WeSpNatWzv0W7Vqlbp37y6r1ar33ntPU6dOVW5urqKiojR+/HiHNaMAAADKmoc7f/natWvVt29fhYeHy2KxaMmSJQ71xhg98cQTCgsLk6+vr3r16qU9e/Y4tDl+/LgGDRokPz8/BQQEaPjw4crOznbhUQAAALhW9+7dZYwpsi1YsECRkZHF1hlj1L17d0lS27Zt9eOPPyojI0M5OTnauXOn4uPjWTMKAAC4lFvvlLLZbGrVqpWGDRumW265pUj9jBkzNGvWLC1cuFBRUVGaPHmyYmNjtXPnTvn4+EiSBg0apCNHjmj58uXKy8vT0KFDNXLkSC1evNjVhwO4TGZmpmw2W4n61qhRQ/7+/k6OCAAAAACAS+PWpFRcXJzi4uKKrTPGaObMmXr88cfVr18/SdJbb72lkJAQLVmyRAMHDlRSUpKWLVumDRs2qH379pKkV155RTfccINeeOEFhYeHu+xYAFfJzMxUZFQDZZw4XqL+AbUDtT/5NxJTAAAAAAC3KrdrSiUnJys1NVW9evWyl/n7+6tjx45KTEzUwIEDlZiYqICAAHtCSpJ69eolDw8PrV+/XjfffLM7QgfKlM1mU8aJ47rusfny9Qu8pL45Wce1/OmhstlsJKUAAAAAAG5VbpNShU+JCQkJcSgPCQmx16WmphZ5bLGnp6cCAwPtbYqTm5ur3Nxc+35WVpazwgZcxtcvUL4Bwe4OAwAAAACAEnHrQufukpCQIH9/f/tWr149d4cEAAAAAABQpZTbpFRoaKgkKS0tzaE8LS3NXhcaGqqjR4861Ofn5+v48eP2NsWJj49XZmamfTt48KCTowcAAAAAAMD5lNukVFRUlEJDQ7VixQp7WVZWltavX6+YmBhJUkxMjDIyMrRp0yZ7m5UrV6qgoEAdO3Y859hWq1V+fn4OGwAAAAAAAFzHrWtKZWdna+/evfb95ORkbdmyRYGBgYqIiNC4ceP01FNPqVGjRoqKitLkyZMVHh6u/v37S5Kio6PVu3dvjRgxQnPnzlVeXp5Gjx6tgQMH8uQ9AAAAAACAcsytSamNGzeqR48e9v0JEyZIkoYMGaIFCxbokUcekc1m08iRI5WRkaEuXbpo2bJl8vHxsfdZtGiRRo8erZ49e8rDw0MDBgzQrFmzXH4sAAAAAAAAuHhuTUp1795dxphz1lssFk2fPl3Tp08/Z5vAwEAtXry4LMIDAAAAAABAGSm3a0oBAAAAAACg8irRnVINGjTQhg0bVKdOHYfyjIwMtW3bVr/99ptTggMAAKgsmD+5V0pKitLT00s9TlJSkhOiAQAAUgmTUvv379fZs2eLlOfm5urQoUOlDgoAAKCyYf7kPikpKWraNFo5OaecNmZe7hmnjQUAQFV1SUmpzz77zP7z119/LX9/f/v+2bNntWLFCkVGRjotOAAAgIqO+ZP7paenKyfnlDoOmyK/sMhSjXVkW6K2fzZP+fn5zgkOAIAq7JKSUv3795f05wLkQ4YMcajz8vJSZGSkXnzxRacFB1R2qampLukDAHAf5k/lh19YpAIjmpRqjKwj+50TDAAAuLSkVEFBgSQpKipKGzZsUFBQUJkEBVR2eTk2yeKhdu3alXiM/PwCJ0YEACgrzJ8AAACKV6I1pZKTk50dB1ClnM07LZkC9Zg4T7WCQi6p74lD+/TdrAkqKCi6LgkAoPxi/gQAAOCoREkpSVqxYoVWrFiho0eP2j8BLPTmm2+WOjCgKrD6Bco3IPiS+pzOOlZG0QAAyhrzJwAAgP9ToqTUtGnTNH36dLVv315hYWGyWCzOjgsAAKBSYf4EAADgqERJqblz52rBggW66667nB0PAABApcT8CQAAwJFHSTqdOXNGnTp1cnYsAAAAlRbzJwAAAEclSkrde++9Wrx4sbNjAQAAqLSYPwEAADgq0df3Tp8+rXnz5unbb79Vy5Yt5eXl5VD/0ksvOSU4AACAyoL5EwAAgKMSJaW2bt2q1q1bS5K2b9/uUMeinQAAAEUxfwIAAHBUoqTUqlWrnB0HAABApcb8CQAAwFGJklIAAAAAyp+kpKRyMQYAABejREmpHj16nPc285UrV5Y4IAAAgMqI+RPKUk7mMUkWDR482Glj5uWecdpYAAAUp0RJqcL1EArl5eVpy5Yt2r59u4YMGeKMuAAAACoV5k8oS3mnTkoyan3nJAVHNS3VWEe2JWr7Z/OUn5/vnOAAADiHEiWlXn755WLLp06dquzs7FIFBAAAUBkxf4Ir1KwbocCIJqUaI+vIfucEAwDABXg4c7DBgwfrzTffdOaQAAAAlRrzJwAAUFU5NSmVmJgoHx8fZw4JAABQqTF/AgAAVVWJvr53yy23OOwbY3TkyBFt3LhRkydPdkpgAAAAlQnzJwAAAEclSkr5+/s77Ht4eKhJkyaaPn26rr/+eqcEBgAAUJkwfwIAAHBUoqTU/PnznR0HAABApcb8CQAAwFGJklKFNm3apKSkJElS8+bN1aZNG6cEBQAAUFkxfwIAAPhTiZJSR48e1cCBA7V69WoFBARIkjIyMtSjRw+99957Cg4OdmaMAAAAFR7zJwAAAEclevremDFjdPLkSe3YsUPHjx/X8ePHtX37dmVlZWns2LHOjhEAAKDCc+b8ae3aterbt6/Cw8NlsVi0ZMkSh3pjjJ544gmFhYXJ19dXvXr10p49exzaHD9+XIMGDZKfn58CAgI0fPhwZWdnl/YwAQAALlqJklLLli3Ta6+9pujoaHtZs2bNNHv2bH311VdOCw4AAKCycOb8yWazqVWrVpo9e3ax9TNmzNCsWbM0d+5crV+/XjVq1FBsbKxOnz5tbzNo0CDt2LFDy5cv19KlS7V27VqNHDmyZAcHAABQAiX6+l5BQYG8vLyKlHt5eamgoKDUQQEAAFQ2zpw/xcXFKS4urtg6Y4xmzpypxx9/XP369ZMkvfXWWwoJCdGSJUs0cOBAJSUladmyZdqwYYPat28vSXrllVd0ww036IUXXlB4ePglHh1QtaWkpCg9Pd0pYwUFBSkiIsIpYwFAeVeipNS1116rBx98UO+++6590nLo0CGNHz9ePXv2dGqAAAAAlYGr5k/JyclKTU1Vr1697GX+/v7q2LGjEhMTNXDgQCUmJiogIMCekJKkXr16ycPDQ+vXr9fNN9/stHiAyi4lJUVNm0YrJ+eUU8bz9a2uXbuSSEwBqBJKlJR69dVXddNNNykyMlL16tWTJB08eFBXXnml3nnnHacGCAAAUBm4av6UmpoqSQoJCXEoDwkJsdelpqaqbt26DvWenp4KDAy0t/m73Nxc5ebm2vezsrKcFjNQkaWnpysn55Q6Dpsiv7DIUo2VdWS/1r85Tenp6SSlAFQJJUpK1atXT5s3b9a3336rXbt2SZKio6MdPpEDAADA/6no86eEhARNmzbN3WEA5ZZfWKQCI5q4OwwAqFAuaaHzlStXqlmzZsrKypLFYtF1112nMWPGaMyYMbrqqqvUvHlzfffdd2UVKwAAQIXj6vlTaGioJCktLc2hPC0tzV4XGhqqo0ePOtTn5+fr+PHj9jZ/Fx8fr8zMTPt28OBBp8UMAACqpktKSs2cOVMjRoyQn59fkTp/f3/dd999eumll5wWHAAAQEXn6vlTVFSUQkNDtWLFCntZVlaW1q9fr5iYGElSTEyMMjIytGnTJnublStXqqCgQB07dix2XKvVKj8/P4cNAACgNC4pKfXLL7+od+/e56y//vrrHSY3AAAAVV1ZzJ+ys7O1ZcsWbdmyRdKfi5tv2bJFKSkpslgsGjdunJ566il99tln2rZtm+6++26Fh4erf//+kv782mDv3r01YsQI/fTTT1q3bp1Gjx6tgQMH8uQ9AADgMpeUlEpLSyv2UcaFPD099ccff5Q6qEJnz57V5MmTFRUVJV9fXzVs2FBPPvmkjDH2NsYYPfHEEwoLC5Ovr6969eqlPXv2OC0GAACA0iiL+dPGjRvVpk0btWnTRpI0YcIEtWnTRk888YQk6ZFHHtGYMWM0cuRIXXXVVcrOztayZcvk4+NjH2PRokVq2rSpevbsqRtuuEFdunTRvHnzSnCEAAAAJXNJC51fdtll2r59u6644opi67du3aqwsDCnBCZJzz33nObMmaOFCxeqefPm2rhxo4YOHSp/f3+NHTtWkjRjxgzNmjVLCxcuVFRUlCZPnqzY2Fjt3LnTYeIFAADgDmUxf+revbvDh3R/Z7FYNH36dE2fPv2cbQIDA7V48eJL+r0AAADOdEl3St1www2aPHmyTp8+XaQuJydHU6ZM0Y033ui04H744Qf169dPffr0UWRkpG699VZdf/31+umnnyT9eZfUzJkz9fjjj6tfv35q2bKl3nrrLR0+fFhLlixxWhwAAAAl5er5EwAAQEVxSXdKPf744/r444/VuHFjjR49Wk2a/PnI0127dmn27Nk6e/asHnvsMacF16lTJ82bN0+//vqrGjdurF9++UXff/+9fTHQ5ORkpaamOjxK2d/fXx07dlRiYqIGDhxY7Li5ubnKzc2172dlZTktZgAAgL9y9fwJAACgorikpFRISIh++OEHPfDAA4qPj7ffNm6xWBQbG6vZs2crJCTEacE9+uijysrKUtOmTVWtWjWdPXtWTz/9tAYNGiRJSk1Ntcf19zgL64qTkJCgadOmOS1OAACAc3H1/AkAAKCiuKSklCTVr19fX375pU6cOKG9e/fKGKNGjRqpdu3aTg/u/fff16JFi7R48WI1b95cW7Zs0bhx4xQeHq4hQ4aUeNz4+HhNmDDBvp+VlaV69eo5I2QAAIAiXDl/AgAAqCguOSlVqHbt2rrqqqucGUsREydO1KOPPmr/Gl6LFi104MABJSQkaMiQIQoNDZX051Nt/rpAaFpamlq3bn3Oca1Wq6xWa5nGDgAA8HeumD8BAABUFJe00LmrnTp1Sh4ejiFWq1ZNBQUFkqSoqCiFhoZqxYoV9vqsrCytX79eMTExLo0VAAAAAAAAF6/Ed0q5Qt++ffX0008rIiJCzZs3188//6yXXnpJw4YNk/TnWgzjxo3TU089pUaNGikqKkqTJ09WeHi4+vfv797gAQAAAAAAcE7lOin1yiuvaPLkyfrnP/+po0ePKjw8XPfdd5+eeOIJe5tHHnlENptNI0eOVEZGhrp06aJly5bJx8fHjZEDAAAAAADgfMp1UqpWrVqaOXOmZs6cec42FotF06dP1/Tp010XGAAAAAAAAEqlXK8pBQAAAAAAgMqJpBQAAAAAAABcjqQUAAAAAAAAXI6kFAAAAAAAAFyOpBQAAAAAAABcjqQUAAAAAAAAXI6kFAAAAAAAAFyOpBQAAAAAAABcjqQUAAAAAAAAXM7T3QEAAAAAAP5PUlKSU8YJCgpSRESEU8YCgLJAUgoAAAAAyoGczGOSLBo8eLBTxvP1ra5du5JITAEot0hKAQAAAEA5kHfqpCSj1ndOUnBU01KNlXVkv9a/OU3p6ekkpQCUWySlAAAAAKAcqVk3QoERTdwdBgCUORY6BwAAAAAAgMuRlAIAAAAAAIDLkZQCAAAAAACAy5GUAgAAAAAAgMux0DlQBaWmpl5ynxo1asjf378MogEAAAAAVEUkpYAqJC/HJlk81K5du0vuG1A7UPuTfyMxBQAAAABwCpJSQBVyNu+0ZArUY+I81QoKueh+OVnHtfzpobLZbCSlAAAAAABOQVIKqIKsfoHyDQi+5H4l+dqfxFf/AAAAAABFkZQCcEGl+dqfxFf/AAAAAABFkZQCcEEl/dqfxFf/AAAAAADFIykF4KKV9Gt/AAAAAAD8nYe7AwAAAAAAAEDVQ1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAACgkomMjJTFYimyjRo1SpLUvXv3InX333+/m6MGAABVDU/fAwAAqGQ2bNigs2fP2ve3b9+u6667Trfddpu9bMSIEZo+fbp9v3r16i6NEQAAgKQUAABAJRMcHOyw/+yzz6phw4bq1q2bvax69eoKDQ11dWgAAAB2fH0PAACgEjtz5ozeeecdDRs2TBaLxV6+aNEiBQUF6corr1R8fLxOnTrlxigBAEBVxJ1SAAAAldiSJUuUkZGhe+65x1525513qn79+goPD9fWrVs1adIk7d69Wx9//PE5x8nNzVVubq59PysrqyzDBgAAVQBJKQAAgErsv//9r+Li4hQeHm4vGzlypP3nFi1aKCwsTD179tS+ffvUsGHDYsdJSEjQtGnTyjxeAABQdZT7r+8dOnRIgwcPVp06deTr66sWLVpo48aN9npjjJ544gmFhYXJ19dXvXr10p49e9wYMQAAQPlw4MABffvtt7r33nvP265jx46SpL17956zTXx8vDIzM+3bwYMHnRorAACoesr1nVInTpxQ586d1aNHD3311VcKDg7Wnj17VLt2bXubGTNmaNasWVq4cKGioqI0efJkxcbGaufOnfLx8XFj9AAAAO41f/581a1bV3369Dlvuy1btkiSwsLCztnGarXKarU6MzzA7ZKSksrFGABQVZXrpNRzzz2nevXqaf78+fayqKgo+8/GGM2cOVOPP/64+vXrJ0l66623FBISoiVLlmjgwIEujxkAAKA8KCgo0Pz58zVkyBB5ev7flG/fvn1avHixbrjhBtWpU0dbt27V+PHj1bVrV7Vs2dKNEQOuk5N5TJJFgwcPdtqYeblnnDYWAFQV5Top9dlnnyk2Nla33Xab1qxZo8suu0z//Oc/NWLECElScnKyUlNT1atXL3sff39/dezYUYmJiSSlAABAlfXtt98qJSVFw4YNcyj39vbWt99+q5kzZ8pms6levXoaMGCAHn/8cTdFCrhe3qmTkoxa3zlJwVFNSzXWkW2J2v7ZPOXn5zsnOACoQsp1Uuq3337TnDlzNGHCBP3rX//Shg0bNHbsWHl7e2vIkCFKTU2VJIWEhDj0CwkJsdcVh6fHAACAyu7666+XMaZIeb169bRmzRo3RASUPzXrRigwokmpxsg6st85wQBAFVSuk1IFBQVq3769nnnmGUlSmzZttH37ds2dO1dDhgwp8bg8PQYAAAAAAMC9yvXT98LCwtSsWTOHsujoaKWkpEiSQkNDJUlpaWkObdLS0ux1xeHpMQAAAAAAAO5VrpNSnTt31u7dux3Kfv31V9WvX1/Sn4ueh4aGasWKFfb6rKwsrV+/XjExMecc12q1ys/Pz2EDAAAAAACA65Trr++NHz9enTp10jPPPKN//OMf+umnnzRv3jzNmzdPkmSxWDRu3Dg99dRTatSokaKiojR58mSFh4erf//+7g0eAAAAAAAA51Suk1JXXXWVPvnkE8XHx2v69OmKiorSzJkzNWjQIHubRx55RDabTSNHjlRGRoa6dOmiZcuWycfHx42RAwAAAAAA4HzKdVJKkm688UbdeOON56y3WCyaPn26pk+f7sKoAAAAAAAAUBrlek0pAAAAAAAAVE4kpQAAAAAAAOByJKUAAAAAAADgciSlAAAAAAAA4HIkpQAAAAAAAOByJKUAAAAAAADgciSlAAAAAAAA4HIkpQAAAAAAAOBynu4OAAAAAABQNpKSkpwyTlBQkCIiIpwyFgAUIikFAAAAAJVMTuYxSRYNHjzYKeP5+lbXrl1JJKYAOBVJKQAAAACoZPJOnZRk1PrOSQqOalqqsbKO7Nf6N6cpPT2dpBQApyIpBQAAAACVVM26EQqMaOLuMACgWCx0DgAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJdjoXMALpGamlqifjVq1JC/v7+TowEAAAAAuBtJKQBlKi/HJlk81K5duxL1D6gdqP3Jv5GYAgAAAIBKhqQUgDJ1Nu+0ZArUY+I81QoKuaS+OVnHtfzpobLZbCSlAAAAAKCSISkFwCWsfoHyDQh2dxgAAAAAgHKChc4BAAAAAADgciSlAAAAAAAA4HIkpQAAAAAAAOByJKUAAAAAAADgciSlAAAAAAAA4HIkpQAAAAAAAOByJKUAAAAAAADgciSlAAAAAAAA4HIkpQAAAAAAAOByJKUAAAAAAADgciSlAAAAAAAA4HIkpQAAACqZqVOnymKxOGxNmza1158+fVqjRo1SnTp1VLNmTQ0YMEBpaWlujBgAAFRFJKUAAAAqoebNm+vIkSP27fvvv7fXjR8/Xp9//rk++OADrVmzRocPH9Ytt9zixmgBAEBV5OnuAAAAAOB8np6eCg0NLVKemZmp//73v1q8eLGuvfZaSdL8+fMVHR2tH3/8UVdffbWrQwUAAFUUd0oBAABUQnv27FF4eLgaNGigQYMGKSUlRZK0adMm5eXlqVevXva2TZs2VUREhBITE885Xm5urrKyshw2AACA0qhQSalnn31WFotF48aNs5exJgIAAICjjh07asGCBVq2bJnmzJmj5ORkXXPNNTp58qRSU1Pl7e2tgIAAhz4hISFKTU0955gJCQny9/e3b/Xq1SvjowAAAJVdhfn63oYNG/T666+rZcuWDuXjx4/XF198oQ8++ED+/v4aPXq0brnlFq1bt85NkTpXZmambDbbJfc736QSAABUbnFxcfafW7ZsqY4dO6p+/fp6//335evrW6Ix4+PjNWHCBPt+VlYWiSkAAFAqFSIplZ2drUGDBumNN97QU089ZS+v7GsiZGZmKjKqgTJOHC/xGPn5BU6MCAAAVEQBAQFq3Lix9u7dq+uuu05nzpxRRkaGw91SaWlpxa5BVchqtcpqtbogWgAAUFVUiKTUqFGj1KdPH/Xq1cshKXWhNRHOlZTKzc1Vbm6ufb+8rolgs9mUceK4rntsvnz9Ai+p74lD+/TdrAkqKDhbRtEBAICKIjs7W/v27dNdd92ldu3aycvLSytWrNCAAQMkSbt371ZKSopiYmLcHCkAAKhKyn1S6r333tPmzZu1YcOGInWlWRNh2rRpzg61zPj6Bco3IPiS+pzOOlZG0QAAgPLu4YcfVt++fVW/fn0dPnxYU6ZMUbVq1XTHHXfI399fw4cP14QJExQYGCg/Pz+NGTNGMTExFf4ucwAAULGU66TUwYMH9eCDD2r58uXy8fFx2risiQAAACqz33//XXfccYeOHTum4OBgdenSRT/++KOCg//8kOvll1+Wh4eHBgwYoNzcXMXGxuq1115zc9QAAKCqKddJqU2bNuno0aNq27atvezs2bNau3atXn31VX399desiQAAAPA377333nnrfXx8NHv2bM2ePdtFEQEAABRVrpNSPXv21LZt2xzKhg4dqqZNm2rSpEmqV68eayIAAAAAAABUQOU6KVWrVi1deeWVDmU1atRQnTp17OWsiQAAAAAAAFDxlOuk1MVgTQQAAAAAAICKp8IlpVavXu2wz5oIAAAAAAAAFY+HuwMAAAAAAABA1UNSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAuR1IKAAAAAAAALkdSCgAAAAAAAC5HUgoAAAAAAAAu5+nuAAAAAAAA5V9SUpJTxgkKClJERIRTxgJQsZGUAgAAAACcU07mMUkWDR482Cnj+fpW165dSSSmAJCUAgAAAACcW96pk5KMWt85ScFRTUs1VtaR/Vr/5jSlp6eTlAJAUgoAAAAAcGE160YoMKKJu8MAUImQlAJQaWVmZspms5Wob40aNeTv7+/kiAAAAAAAhUhKAaiUMjMzFRnVQBknjpeof0DtQO1P/o3EFAAAAACUEZJSAMq91NTUEvXJOHFc1z02X75+gZfUNyfruJY/PVQ2m42kFAAAAACUEZJSAMqtvBybZPFQu3btSjyGV/UA+QYEOzEqAAAAAIAzkJQCUG6dzTstmQL1mDhPtYJCLqnviUP79N2sCSooOFtG0QEAAKCkkpKSnDJOUFAQT/EDKjCSUgDKPatf4CXf7XQ661gZRQMAAICSysk8JsmiwYMHO2U8X9/q2rUricQUUEGRlAIAAAAAuETeqZOSjFrfOUnBUU1LNVbWkf1a/+Y0paenk5QCKiiSUgAAAAAAl6pZN0KBEU3cHQYANyMpBQAAAACosFifCqi4SEq5QGZmpmw22yX3S01NLYNoAAAAAKDiY30qoOIjKVXGMjMzFRnVQBknjpd4jPz8AidGBAAAAAAVH+tTARUfSakyZrPZlHHiuK57bL58/QIvqS+PtAcAAACA82N9KqDiIinlIr480h4AAAAAAMDOw90BAAAAAAAAoOohKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAUMkkJCToqquuUq1atVS3bl31799fu3fvdmjTvXt3WSwWh+3+++93U8QAAKAqIikFAABQyaxZs0ajRo3Sjz/+qOXLlysvL0/XX3+9bDabQ7sRI0boyJEj9m3GjBluihgAAFRFnu4OAAAAAM61bNkyh/0FCxaobt262rRpk7p27Wovr169ukJDQ10dHgAAgKQKcKfUxdx+fvr0aY0aNUp16tRRzZo1NWDAAKWlpbkpYgAAgPIlMzNTkhQYGOhQvmjRIgUFBenKK69UfHy8Tp065Y7wAABAFVXuk1IXc/v5+PHj9fnnn+uDDz7QmjVrdPjwYd1yyy1ujBoAAKB8KCgo0Lhx49S5c2ddeeWV9vI777xT77zzjlatWqX4+Hi9/fbbGjx48DnHyc3NVVZWlsMGAABQGuX+63sXuv08MzNT//3vf7V48WJde+21kqT58+crOjpaP/74o66++mp3hA0AAFAujBo1Stu3b9f333/vUD5y5Ej7zy1atFBYWJh69uypffv2qWHDhkXGSUhI0LRp08o8XgAAUHWU+zul/u7vt59v2rRJeXl56tWrl71N06ZNFRERocTExGLH4JM+AABQFYwePVpLly7VqlWrdPnll5+3bceOHSVJe/fuLbY+Pj5emZmZ9u3gwYNOjxcAAFQtFSopVdzt56mpqfL29lZAQIBD25CQEKWmphY7TkJCgvz9/e1bvXr1yjp0AAAAlzHGaPTo0frkk0+0cuVKRUVFXbDPli1bJElhYWHF1lutVvn5+TlsAAAApVHuv773V+e6/fxSxcfHa8KECfb9rKwsElMAAKDSGDVqlBYvXqxPP/1UtWrVsn9Q5+/vL19fX+3bt0+LFy/WDTfcoDp16mjr1q0aP368unbtqpYtW7o5egAAUFVUmKRU4e3na9eudbj9PDQ0VGfOnFFGRobD3VJpaWnnfMSx1WqV1Wot65ABAADcYs6cOZKk7t27O5TPnz9f99xzj7y9vfXtt99q5syZstlsqlevngYMGKDHH3/cDdECAICqqtwnpYwxGjNmjD755BOtXr26yO3n7dq1k5eXl1asWKEBAwZIknbv3q2UlBTFxMS4I2QAAAC3Msact75evXpas2aNi6IBAAAoXrlPSl3o9nN/f38NHz5cEyZMUGBgoPz8/DRmzBjFxMTw5D0AAAAAAIByqtwnpS50+7kkvfzyy/Lw8NCAAQOUm5ur2NhYvfbaay6OFAAAAABQkSUlJTllnKCgIEVERDhlLKAyK/dJqQvdfi5JPj4+mj17tmbPnu2CiAAAAAAAlUlO5jFJFg0ePNgp4/n6VteuXUkkpoALKPdJKQAAAAAAylLeqZOSjFrfOUnBUU1LNVbWkf1a/+Y0paenk5QCLoCkFACcQ+EadpeiRo0a8vf3L4NoAAAAUNZq1o1QYEQTd4cBVBkkpQDgb/JybJLFQ+3atbvkvgG1A7U/+TcSUwAAAABwASSlAOBvzuadlkyBekycp1pBIRfdLyfruJY/PVQ2m42kFAAAAEotJSVF6enpThmLxddRHpGUAoBzsPoFyjcg2N1hAAAAoApKSUlR06bRysk55ZTxWHwd5RFJKQAAAAAAypn09HTl5JxSx2FT5BcWWaqxWHwd5RVJKQAAAAAAyim/sEgWX0el5eHuAAAAAAAAAFD1cKcUAJQTmZmZstlsJepbo0YNFlcHAAAAUKGQlAKAciAzM1ORUQ2UceJ4ifoH1A7U/uTfSEwBAACUE0lJSW7tD1QEJKUAoByw2WzKOHFc1z02X75+gZfUNyfruJY/PVQ2m42kFAAAgJvlZB6TZNHgwYOdMl5e7hmnjAOURySlAKAc8fULlG9AsLvDAAAAQAnlnTopyaj1nZMUHNW0xOMc2Zao7Z/NU35+vvOCA8oZklIAAAAAADhZzboRpXpqXtaR/c4LBiinePoeAAAAAAAAXI6kFAAAAAAAAFyOr+8BAEosMzNTNputRH1r1KjBwuwAAABAFUZSCgBQIpmZmYqMaqCME8dL1D+gdqD2J/9GYgoAAACookhKAQBKxGazKePEcV332Hz5+gVeUt+crONa/vRQ2Ww2klIAziklJUXp6emlHicpKckJ0QBAxees18OgoCBFREQ4ZSxUbSSlAACl4usXKN+AYHeHAaCSSUlJUdOm0crJOeW0MfNyzzhtLACoSHIyj0myaPDgwU4Zz9e3unbtSiIxhVIjKQUAAIByJz09XTk5p9Rx2BT5hUWWaqwj2xK1/bN5ys/Pd05wAFDB5J06Kcmo9Z2TFBzVtFRjZR3Zr/VvTtN3332n6OjoUsfGXVdVG0kpAAAAlFt+YZEKjGhSqjGyjux3TjAAUMHVrBtR6tdU7rqCM5GUAgAAAAAAF6Us7rpKT08nKVVFkZQCACdLTU11SZ/KoCTHXaNGDRZHBwAAcDNn3HUFkJQCACfJy7FJFg+1a9euxGPk5xc4MaLyqzTnKqB2oPYn/0ZiCgAAAKjgSEoBgJOczTstmQL1mDhPtYJCLqnviUP79N2sCSooOFtG0ZUvJT1XOVnHtfzpobLZbCSlAAAAgAqOpBQAOJnVL1C+AcGX1Od01rEyiqZ8K8m5AgAAAFA5eLg7AAAAAAAAAFQ9JKUAAAAAAADgcnx9DwAqiZI+wS8/P1+enpf+duDOJwaW9HeX5sl9mZmZstlsJepb0nMs8bRBAAAAVF4kpQCggivtU/8sHtVkSrHAuiufGFjaYy3pk/syMzMVGdVAGSeOl+j3luYc87RBAAAAVFYkpQCggnPGU/8qyhMDS3OspXlyn81mU8aJ47rusfny9Qu8pL6lOcc8bRAAAODipaSkKD093SljBQUFKSIiwilj4dxISgFAJVGap/5VtCcGuuupfb4uPscAAAC4OCkpKWraNFo5OaecMp6vb3Xt2pVEYqqMkZQCAAAAAAAVWnp6unJyTqnjsCnyC4ss1VhZR/Zr/ZvTlJ6eTlKqjJGUAgBUKSVZJN2di7qX5vezSDoAAKhq/MIiFRjRxN1h4CJVmqTU7Nmz9fzzzys1NVWtWrXSK6+8og4dOrg7LABAOVHaRdIl1y7qLrlvYXdULcyhAADulpSUVC7GKKsxc3NzZbVay91Y5WHdrEqRlPrf//6nCRMmaO7cuerYsaNmzpyp2NhY7d69W3Xr1nV3eACAcsAZC8K7clF3yX0Lu2dmZspms11Sn0L5+fny9CzZ9KI0fbkrrGSYQwEA3Ckn85gkiwYPHuy0MfNyz5R6DKfHZbFIxpS7scrDulmVIin10ksvacSIERo6dKgkae7cufriiy/05ptv6tFHH3VzdACA8qSiLeouuXaR9MzMTEVGNVDGieMl6m/xqCZTwuRdafpyV1jJMIcCALhT3qmTkoxa3zlJwVFNSzXWkW2J2v7ZPOXn55fLuMrbWOVl3awKn5Q6c+aMNm3apPj4eHuZh4eHevXqpcTERDdGBgBAxWOz2ZRx4riue2y+fP0CL6lv4R1lpbkbzdV3hVVlzKEAAOVFzboRpV4HKuvIfucE8xfOjKu8jVVeVPikVHp6us6ePauQEMcJbEhIiHbt2lVsn9zcXOXm5tr3MzMzJUlZWVlOj+/kyZN//vePQ8o7fWmPpjyZ/ufCtrY/DslSkEffcvQ7q1rfihavu/pWtHgrYt+KFq87+54+eUKStHfvXvt70cVIS0uTJOXn5lzy+1Z+7mk39c2R9Od7blm8lxeOaZx12305calzKFfOnyQpOztbknT8wG77NS6prCMHJEmZh/bIy9PCWIzFWIxVIcYqjzExViUaKzVF0p/vt26dP5kK7tChQ0aS+eGHHxzKJ06caDp06FBsnylTphhJbGxsbGxsbGwXvR08eNAVUxuXudQ5FPMnNjY2NjY2tkvdLjR/qvB3SgUFBalatWr2T3YLpaWlKTQ0tNg+8fHxmjBhgn2/oKBAx48fV506dWSxlC7b+HdZWVmqV6+eDh48KD8/P6eODefhOlUMXKeKgetUMXCdLp4xRidPnlR4eLi7Q3GqS51DuXL+JPE3WhzOiSPOR1Gck6I4J0VxThxxPopyxjm52PlThU9KeXt7q127dlqxYoX69+8v6c9J0ooVKzR69Ohi+1it1iKPUAwICCjTOP38/PgDrwC4ThUD16li4DpVDFyni1MZ16q61DmUO+ZPEn+jxeGcOOJ8FMU5KYpzUhTnxBHno6jSnpOLmT9V+KSUJE2YMEFDhgxR+/bt1aFDB82cOVM2m83+JBkAAAAUxRwKAAC4U6VISt1+++36448/9MQTTyg1NVWtW7fWsmXLiizcCQAAgP/DHAoAALhTpUhKSdLo0aPP+XU9d7JarZoyZUqR291RvnCdKgauU8XAdaoYuE4oxByq4uCcOOJ8FMU5KYpzUhTnxBHnoyhXnhOLMZXs+cYAAAAAAAAo9zzcHQAAAAAAAACqHpJSAAAAAAAAcDmSUgAAAAAAAHA5klJlbPbs2YqMjJSPj486duyon376yd0hVRlTp06VxWJx2Jo2bWqvP336tEaNGqU6deqoZs2aGjBggNLS0hzGSElJUZ8+fVS9enXVrVtXEydOVH5+vqsPpVJZu3at+vbtq/DwcFksFi1ZssSh3hijJ554QmFhYfL19VWvXr20Z88ehzbHjx/XoEGD5Ofnp4CAAA0fPlzZ2dkObbZu3aprrrlGPj4+qlevnmbMmFHWh1apXOg63XPPPUX+/+rdu7dDG65T2UpISNBVV12lWrVqqW7duurfv792797t0MZZr3OrV69W27ZtZbVadcUVV2jBggVlfXio4qry/MkZ75OVjbNe7yqLOXPmqGXLlvLz85Ofn59iYmL01Vdf2eur0rk4l2effVYWi0Xjxo2zl1W18+KMfwtVRocOHdLgwYNVp04d+fr6qkWLFtq4caO9vqq9xkZGRhb5O7FYLBo1apQk1/ydkJQqQ//73/80YcIETZkyRZs3b1arVq0UGxuro0ePuju0KqN58+Y6cuSIffv+++/tdePHj9fnn3+uDz74QGvWrNHhw4d1yy232OvPnj2rPn366MyZM/rhhx+0cOFCLViwQE888YQ7DqXSsNlsatWqlWbPnl1s/YwZMzRr1izNnTtX69evV40aNRQbG6vTp0/b2wwaNEg7duzQ8uXLtXTpUq1du1YjR46012dlZen6669X/fr1tWnTJj3//POaOnWq5s2bV+bHV1lc6DpJUu/evR3+/3r33Xcd6rlOZWvNmjUaNWqUfvzxRy1fvlx5eXm6/vrrZbPZ7G2c8TqXnJysPn36qEePHtqyZYvGjRune++9V19//bVLjxdVR1WfPznjfbKyccbrXWVy+eWX69lnn9WmTZu0ceNGXXvtterXr5927NghqWqdi+Js2LBBr7/+ulq2bOlQXhXPS2n+LVQZnThxQp07d5aXl5e++uor7dy5Uy+++KJq165tb1PVXmM3bNjg8DeyfPlySdJtt90myUV/JwZlpkOHDmbUqFH2/bNnz5rw8HCTkJDgxqiqjilTpphWrVoVW5eRkWG8vLzMBx98YC9LSkoykkxiYqIxxpgvv/zSeHh4mNTUVHubOXPmGD8/P5Obm1umsVcVkswnn3xi3y8oKDChoaHm+eeft5dlZGQYq9Vq3n33XWOMMTt37jSSzIYNG+xtvvrqK2OxWMyhQ4eMMca89tprpnbt2g7XadKkSaZJkyZlfESV09+vkzHGDBkyxPTr1++cfbhOrnf06FEjyaxZs8YY47zXuUceecQ0b97c4XfdfvvtJjY2tqwPCVUU86f/U5L3yaqgJK93lV3t2rXNf/7znyp/Lk6ePGkaNWpkli9fbrp162YefPBBY0zV/Bsp7b+FKqNJkyaZLl26nLOe11hjHnzwQdOwYUNTUFDgsr8T7pQqI2fOnNGmTZvUq1cve5mHh4d69eqlxMREN0ZWtezZs0fh4eFq0KCBBg0apJSUFEnSpk2blJeX53B9mjZtqoiICPv1SUxMVIsWLRQSEmJvExsbq6ysLPsnUXCu5ORkpaamOlwXf39/dezY0eG6BAQEqH379vY2vXr1koeHh9avX29v07VrV3l7e9vbxMbGavfu3Tpx4oSLjqbyW716terWrasmTZrogQce0LFjx+x1XCfXy8zMlCQFBgZKct7rXGJiosMYhW14L0NZYP50fhfzPlkVlOT1rrI6e/as3nvvPdlsNsXExFTpcyFJo0aNUp8+fYq8b1XV81KafwtVRp999pnat2+v2267TXXr1lWbNm30xhtv2Our+mvsmTNn9M4772jYsGGyWCwu+zshKVVG0tPTdfbsWYeJviSFhIQoNTXVTVFVLR07dtSCBQu0bNkyzZkzR8nJybrmmmt08uRJpaamytvbWwEBAQ59/np9UlNTi71+hXVwvsLzer7/b1JTU1W3bl2Hek9PTwUGBnLtXKh379566623tGLFCj333HNas2aN4uLidPbsWUlcJ1crKCjQuHHj1LlzZ1155ZWS5LTXuXO1ycrKUk5OTlkcDqow5k/ndzHvk5VdSV/vKptt27apZs2aslqtuv/++/XJJ5+oWbNmVfJcFHrvvfe0efNmJSQkFKmriueltP8Wqox+++03zZkzR40aNdLXX3+tBx54QGPHjtXChQsl8Rq7ZMkSZWRk6J577pHkuv9vPJ02ElDOxMXF2X9u2bKlOnbsqPr16+v999+Xr6+vGyMDKr6BAwfaf27RooVatmyphg0bavXq1erZs6cbI6uaRo0ape3btzusFQEAlRGvd39q0qSJtmzZoszMTH344YcaMmSI1qxZ4+6w3ObgwYN68MEHtXz5cvn4+Lg7nHKBfwsVVVBQoPbt2+uZZ56RJLVp00bbt2/X3LlzNWTIEDdH537//e9/FRcXp/DwcJf+Xu6UKiNBQUGqVq1akZXp09LSFBoa6qaoqraAgAA1btxYe/fuVWhoqM6cOaOMjAyHNn+9PqGhocVev8I6OF/heT3f/zehoaFFFrvNz8/X8ePHuXZu1KBBAwUFBWnv3r2SuE6uNHr0aC1dulSrVq3S5Zdfbi931uvcudr4+flV2Uktyg7zp/O7mPfJyqw0r3eVjbe3t6644gq1a9dOCQkJatWqlf79739XyXMh/fl1tKNHj6pt27by9PSUp6en1qxZo1mzZsnT01MhISFV8rz81aX+W6gyCgsLU7NmzRzKoqOj7V9rrMqvsQcOHNC3336re++9117mqr8TklJlxNvbW+3atdOKFSvsZQUFBVqxYoViYmLcGFnVlZ2drX379iksLEzt2rWTl5eXw/XZvXu3UlJS7NcnJiZG27Ztc/iH9fLly+Xn51fkxQzOERUVpdDQUIfrkpWVpfXr1ztcl4yMDG3atMneZuXKlSooKFDHjh3tbdauXau8vDx7m+XLl6tJkyYOT9eA8/z+++86duyYwsLCJHGdXMEYo9GjR+uTTz7RypUrFRUV5VDvrNe5mJgYhzEK2/BehrLA/On8LuZ9sjJyxutdZVdQUKDc3Nwqey569uypbdu2acuWLfatffv2GjRokP3nqnhe/upS/y1UGXXu3Fm7d+92KPv1119Vv359SVX3NVaS5s+fr7p166pPnz72Mpf9nThtyXQU8d577xmr1WoWLFhgdu7caUaOHGkCAgIcnnKEsvPQQw+Z1atXm+TkZLNu3TrTq1cvExQUZI4ePWqMMeb+++83ERERZuXKlWbjxo0mJibGxMTE2Pvn5+ebK6+80lx//fVmy5YtZtmyZSY4ONjEx8e765AqhZMnT5qff/7Z/Pzzz0aSeemll8zPP/9sDhw4YIwx5tlnnzUBAQHm008/NVu3bjX9+vUzUVFRJicnxz5G7969TZs2bcz69evN999/bxo1amTuuOMOe31GRoYJCQkxd911l9m+fbt57733TPXq1c3rr7/u8uOtqM53nU6ePGkefvhhk5iYaJKTk823335r2rZtaxo1amROnz5tH4PrVLYeeOAB4+/vb1avXm2OHDli306dOmVv44zXud9++81Ur17dTJw40SQlJZnZs2ebatWqmWXLlrn0eFF1VPX5kzPeJysbZ7zeVSaPPvqoWbNmjUlOTjZbt241jz76qLFYLOabb74xxlStc3E+f336njFV77yU9t9CldFPP/1kPD09zdNPP2327NljFi1aZKpXr27eeecde5uq+Bp79uxZExERYSZNmlSkzhV/JySlytgrr7xiIiIijLe3t+nQoYP58ccf3R1SlXH77bebsLAw4+3tbS677DJz++23m71799rrc3JyzD//+U9Tu3ZtU716dXPzzTebI0eOOIyxf/9+ExcXZ3x9fU1QUJB56KGHTF5enqsPpVJZtWqVkVRkGzJkiDHmz0exTp482YSEhBir1Wp69uxpdu/e7TDGsWPHzB133GFq1qxp/Pz8zNChQ83Jkycd2vzyyy+mS5cuxmq1mssuu8w8++yzrjrESuF81+nUqVPm+uuvN8HBwcbLy8vUr1/fjBgxosg/GLlOZau46yPJzJ8/397GWa9zq1atMq1btzbe3t6mQYMGDr8DKAtVef7kjPfJysZZr3eVxbBhw0z9+vWNt7e3CQ4ONj179rQnpIypWufifP6elKpq58UZ/xaqjD7//HNz5ZVXGqvVapo2bWrmzZvnUF8VX2O//vprI6nY43TF34nFGGOcd98VAAAAAAAAcGGsKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAAAAAAAJcjKQUAAAAAAACXIykFAAAAAAAAlyMpBQAusn//flksFm3ZssXdoQAAgHPo3r27xo0b57bfHxkZqZkzZ5Z6nHvuuUf9+/cv9TjlHfMroGIjKQWgxBYsWKCAgAB3hwE3mTp1qlq3bu3uMAAAqFQ2bNigkSNHXnT7cyVl/v3vf2vBggXODQ5ljvkVqhpPdwcAAJXNmTNn5O3t7e4wAABABVI4fwgODnbKeP7+/k4Zp7xgfgVUTtwpBVRyH374oVq0aCFfX1/VqVNHvXr1ks1mkyT95z//UXR0tHx8fNS0aVO99tpr9n6Fn7p9/PHH6tGjh6pXr65WrVopMTFRkrR69WoNHTpUmZmZslgsslgsmjp1qiQpNzdXDz/8sC677DLVqFFDHTt21OrVq+1jF95h9fXXXys6Olo1a9ZU7969deTIEYfY33zzTTVv3lxWq1VhYWEaPXq0vS4jI0P33nuvgoOD5efnp2uvvVa//PLLBc9HZmamqlWrpo0bN0qSCgoKFBgYqKuvvtre5p133lG9evXs+9u2bdO1115rP4cjR45Udna2vb7w9vinn35a4eHhatKkiSTpp59+Ups2beTj46P27dvr559/dojlxIkTGjRokIKDg+Xr66tGjRpp/vz5FzwGSfr99991xx13KDAwUDVq1FD79u21fv16e/2cOXPUsGFDeXt7q0mTJnr77bftdcV9opqRkSGLxWK/TqtXr5bFYtGKFSvUvn17Va9eXZ06ddLu3bsl/XkNp02bpl9++cV+/fk0FgBQ0dhsNt19992qWbOmwsLC9OKLLzrUX2hOc+DAAfXt21e1a9dWjRo11Lx5c3355Zf2+h07dujGG2+Un5+fatWqpWuuuUb79u2TdO75w9+/vmexWDRnzhzFxcXJ19dXDRo00Icffmivj4qKkiS1adNGFotF3bt3dxj/r8cyduxY1a1bVz4+PurSpYs2bNhgr7/Qe//5ML9ifgWUFEkpoBI7cuSI7rjjDg0bNkxJSUlavXq1brnlFhljtGjRIj3xxBN6+umnlZSUpGeeeUaTJ0/WwoULHcZ47LHH9PDDD2vLli1q3Lix7rjjDuXn56tTp06aOXOm/Pz8dOTIER05ckQPP/ywJGn06NFKTEzUe++9p61bt+q2225T7969tWfPHvu4p06d0gsvvKC3335ba9euVUpKir2/9Oeb/qhRozRy5Eht27ZNn332ma644gp7/W233aajR4/qq6++0qZNm9S2bVv17NlTx48fP+858ff3V+vWre2Tg23btslisejnn3+2T4TWrFmjbt26SfpzshobG6vatWtrw4YN+uCDD/Ttt986JMgkacWKFdq9e7eWL1+upUuXKjs7WzfeeKOaNWumTZs2aerUqQ7HJ0mTJ0/Wzp079dVXXykpKUlz5sxRUFDQBa9rdna2unXrpkOHDumzzz7TL7/8okceeUQFBQWSpE8++UQPPvigHnroIW3fvl333Xefhg4dqlWrVl1w7L977LHH9OKLL2rjxo3y9PTUsGHDJEm33367HnroITVv3tx+/W+//fZLHh8AAHeaOHGi1qxZo08//VTffPONVq9erc2bN9vrLzSnGTVqlHJzc7V27Vpt27ZNzz33nGrWrClJOnTokLp27Sqr1aqVK1dq06ZNGjZsmPLz8+3j/33+cC6TJ0/WgAED9Msvv2jQoEEaOHCgkpKSJP2ZpJGkb7/9VkeOHNHHH39c7BiPPPKIPvroIy1cuFCbN2/WFVdcodjY2CJzp3O9958P86tLw/wK+AsDoNLatGmTkWT2799fpK5hw4Zm8eLFDmVPPvmkiYmJMcYYk5ycbCSZ//znP/b6HTt2GEkmKSnJGGPM/Pnzjb+/v8MYBw4cMNWqVTOHDh1yKO/Zs6eJj4+395Nk9u7da6+fPXu2CQkJse+Hh4ebxx57rNjj+u6774yfn585ffp0kWN6/fXXi+3zVxMmTDB9+vQxxhgzc+ZMc/vtt5tWrVqZr776yhhjzBVXXGHmzZtnjDFm3rx5pnbt2iY7O9ve/4svvjAeHh4mNTXVGGPMkCFDTEhIiMnNzbW3ef31102dOnVMTk6OvWzOnDlGkvn555+NMcb07dvXDB069ILx/t3rr79uatWqZY4dO1ZsfadOncyIESMcym677TZzww03GGP+79oWxmGMMSdOnDCSzKpVq4wxxqxatcpIMt9++63DcUuyH9OUKVNMq1atLjl+AADKg5MnTxpvb2/z/vvv28uOHTtmfH19zYMPPnhRc5oWLVqYqVOnFjt+fHy8iYqKMmfOnCm2vrj5gzHG1K9f37z88sv2fUnm/vvvd2jTsWNH88ADDxhjin9fLxy/X79+xhhjsrOzjZeXl1m0aJG9/syZMyY8PNzMmDHDGHNx7/3nw/yK+RVQEtwpBVRirVq1Us+ePdWiRQvddttteuONN3TixAnZbDbt27dPw4cPV82aNe3bU089Zb+lvFDLli3tP4eFhUmSjh49es7fuW3bNp09e1aNGzd2GHvNmjUOY1evXl0NGzZ0GLtw3KNHj+rw4cPq2bNnsb/jl19+UXZ2turUqePwO5KTk4vEX5xu3brp+++/19mzZ7VmzRp1795d3bt31+rVq3X48GHt3bvXfut7UlKSWrVqpRo1atj7d+7cWQUFBQ63s7do0cJhnYOkpCS1bNlSPj4+9rKYmBiHOB544AG99957at26tR555BH98MMPF4xdkrZs2aI2bdooMDCw2PqkpCR17tzZoaxz5872T1QvxaVefwAAKop9+/bpzJkz6tixo70sMDDQ/jWxi5nTjB07Vk899ZQ6d+6sKVOmaOvWrfaxtmzZomuuuUZeXl7njOHv84dz+fscIiYm5pLe1/ft26e8vDyH+YGXl5c6dOhQZJySvvczv7p4zK+A/8NC50AlVq1aNS1fvlw//PCDvvnmG73yyit67LHH9Pnnn0uS3njjDYeJWGGfv/rrRMpisUiS/Tbm4mRnZ6tatWratGlTkbEKb2f/+7iFYxtjJEm+vr7nPa7s7GyFhYU5rOlQ6GKeBti1a1edPHlSmzdv1tq1a/XMM88oNDRUzz77rFq1aqXw8HA1atToguP81V8nVRcrLi5OBw4c0Jdffqnly5erZ8+eGjVqlF544YXz9rvQ+bkQD48/P48oPN+SlJeXV2zbS73+AABUFhczp7n33nsVGxurL774Qt98840SEhL04osvasyYMRf1fl2S+UNZK+l7P/Mr5ldASXCnFFDJWSwWde7cWdOmTdPPP/8sb29vrVu3TuHh4frtt990xRVXOGyFi2VeDG9vb509e9ahrE2bNjp79qyOHj1aZOzQ0NCLGrdWrVqKjIzUihUriq1v27atUlNT5enpWeR3XMyaAQEBAWrZsqVeffVVeXl5qWnTpuratat+/vlnLV261L7egSRFR0frl19+sS8OL0nr1q2Th4eH/ZPU4kRHR2vr1q06ffq0vezHH38s0i44OFhDhgzRO++8o5kzZ2revHkXjL9ly5basmXLOdfPio6O1rp16xzK1q1bp2bNmtl/pySHheX//hjpi1Hc9QcAoKJo2LChvLy8HBayPnHihH799VdJFz+nqVevnu6//359/PHHeuihh/TGG29I+vP9+rvvvjtnYuJS/H0O8eOPPyo6OlqS7HcSne89uXBx7r/OD/Ly8rRhwwb7/KC0mF8xvwJKgqQUUImtX79ezzzzjDZu3KiUlBR9/PHH+uOPPxQdHa1p06YpISFBs2bN0q+//qpt27Zp/vz5eumlly56/MjISGVnZ2vFihVKT0/XqVOn1LhxYw0aNEh33323Pv74YyUnJ+unn35SQkKCvvjii4see+rUqXrxxRc1a9Ys7dmzR5s3b9Yrr7wiSerVq5diYmLUv39/ffPNN9q/f79++OEHPfbYY/anvlxI9+7dtWjRIvsEKTAwUNHR0frf//7nMGkaNGiQfHx8NGTIEG3fvl2rVq3SmDFjdNdddykkJOSc4995552yWCwaMWKEdu7cqS+//LLIJ3RPPPGEPv30U+3du1c7duzQ0qVL7RPM87njjjsUGhqq/v37a926dfrtt9/00Ucf2Z+MOHHiRC1YsEBz5szRnj179NJLL+njjz+2LwTq6+urq6++Ws8++6ySkpK0Zs0aPf744xd13v4qMjJSycnJ2rJli9LT05Wbm3vJYwAA4C41a9bU8OHDNXHiRK1cuVLbt2/XPffcY7/j5WLmNOPGjdPXX3+t5ORkbd68WatWrbK/l48ePVpZWVkaOHCgNm7cqD179ujtt9++qKfZ/d0HH3ygN998U7/++qumTJmin376yb4oeN26deXr66tly5YpLS1NmZmZRfrXqFFDDzzwgCZOnKhly5Zp586dGjFihE6dOqXhw4eX9BQWwfyK+RVwydy8phWAMrRz504TGxtrgoODjdVqNY0bNzavvPKKvX7RokWmdevWxtvb29SuXdt07drVfPzxx8aYi1us0Rhj7r//flOnTh0jyUyZMsUY8+fCmU888YSJjIw0Xl5eJiwszNx8881m69atxpjiF0j/5JNPzN9fkubOnWuaNGliH2PMmDH2uqysLDNmzBgTHh5uvLy8TL169cygQYNMSkrKRZ2bwt83Z84ce9mDDz5oJJldu3Y5tN26davp0aOH8fHxMYGBgWbEiBHm5MmT9vq/LiT6V4mJiaZVq1bG29vbtG7d2nz00UcO5/TJJ5800dHRxtfX1wQGBpp+/fqZ33777aLi379/vxkwYIDx8/Mz1atXN+3btzfr16+317/22mumQYMGxsvLyzRu3Ni89dZbDv137txpYmJijK+vr2ndurX55ptvil2I88SJE/Y+P//8s5FkkpOTjTHGnD592gwYMMAEBAQYSWb+/PkXFTsAAOXFyZMnzeDBg0316tVNSEiImTFjhunWrZt58MEHjTEXntOMHj3aNGzY0FitVhMcHGzuuusuk56ebh//l19+Mddff72pXr26qVWrlrnmmmvMvn37jDHnnj8Ut9D57NmzzXXXXWesVquJjIw0//vf/xz6vPHGG6ZevXrGw8PDdOvWrdjxc3JyzJgxY0xQUJCxWq2mc+fO5qeffrLXX8x7/4Uwv2J+BVwqizF/+dIrAAAAAKDcsFgs+uSTT9S/f393hwIATsfX9wAAAAAAAOByJKUAVDrNmzd3eHTzX7dFixa5O7wLeuaZZ84Zf1xcnLvDAwAAVRDzKwBlga/vAah0Dhw4cM4n3YSEhKhWrVoujujSHD9+/JxPfvH19dVll13m4ogAAEBVx/zq/7VvxzQAAAAMwvy7nopxtTJIAB5EKQAAAABy9j0AAAAAcqIUAAAAADlRCgAAAICcKAUAAABATpQCAAAAICdKAQAAAJATpQAAAADIiVIAAAAA5AbZlvrAMs3e9gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize = (12,5))\n",
    "sns.histplot(data = df, x = 'sentence_words_count', ax = axes[0]).set_title('Transcription Words')\n",
    "sns.histplot(data = df, x = 'description_words_count', ax = axes[1]).set_title('Description Words')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:47:37.991017Z",
     "iopub.status.busy": "2025-07-20T12:47:37.990738Z",
     "iopub.status.idle": "2025-07-20T12:47:37.996018Z",
     "shell.execute_reply": "2025-07-20T12:47:37.994910Z",
     "shell.execute_reply.started": "2025-07-20T12:47:37.990996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median of words in the transcription : 492.5\n",
      "max of words in the transcription : 2242\n"
     ]
    }
   ],
   "source": [
    "print('median of words in the transcription :', df['sentence_words_count'].median())\n",
    "print('max of words in the transcription :', df['sentence_words_count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:47:28.654518Z",
     "iopub.status.busy": "2025-07-20T12:47:28.654200Z",
     "iopub.status.idle": "2025-07-20T12:47:28.659243Z",
     "shell.execute_reply": "2025-07-20T12:47:28.658588Z",
     "shell.execute_reply.started": "2025-07-20T12:47:28.654496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median of words in the description : 17.0\n",
      "max of words in the description : 69\n"
     ]
    }
   ],
   "source": [
    "print('median of words in the description :', df['description_words_count'].median())\n",
    "print('max of words in the description :', df['description_words_count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:47:43.771628Z",
     "iopub.status.busy": "2025-07-20T12:47:43.771331Z",
     "iopub.status.idle": "2025-07-20T12:50:24.276168Z",
     "shell.execute_reply": "2025-07-20T12:50:24.275393Z",
     "shell.execute_reply.started": "2025-07-20T12:47:43.771607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d664557e734f7996d423586f43079d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c81620737a14db4814919fdf32baf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3aa5597044140858ccec71761c19aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2660a7aea54c23affbc492b0532ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0787221222d04dc69ee2deeed7692819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba208069985425f95ed46865fbdd962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9e82d8c23e43e5a4ec8816489917a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfa45cfae164d519c16d8c68a0d445c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300b3aaef77a493ea32f6a6c397f911c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb022cbccde44c08a4e05423f9d25870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cf0f9a715e4254a74e3563f55d9903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_keywords_keybert(text, top_k=22):\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), top_n=top_k)\n",
    "    return ' '.join([kw for kw, _ in keywords])\n",
    "\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "df['cleaned_transcript'] = df['transcription'].apply(extract_keywords_keybert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:54:15.411944Z",
     "iopub.status.busy": "2025-07-20T12:54:15.411644Z",
     "iopub.status.idle": "2025-07-20T12:54:15.426228Z",
     "shell.execute_reply": "2025-07-20T12:54:15.425401Z",
     "shell.execute_reply.started": "2025-07-20T12:54:15.411924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median words after cleaning :  41.0\n",
      "max words after cleaning :  44\n"
     ]
    }
   ],
   "source": [
    "df['sentence_words_count_after'] = df['cleaned_transcript'].str.split().str.len()\n",
    "print('median words after cleaning : ',df['sentence_words_count_after'].median())\n",
    "print('max words after cleaning : ',df['sentence_words_count_after'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:47:51.877777Z",
     "iopub.status.busy": "2025-07-20T08:47:51.877530Z",
     "iopub.status.idle": "2025-07-20T08:48:05.580991Z",
     "shell.execute_reply": "2025-07-20T08:48:05.580156Z",
     "shell.execute_reply.started": "2025-07-20T08:47:51.877755Z"
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "5eff0d61-05b4-471c-eea2-c2e84a915109",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Granite patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c514969deea41e5b59725b9e33b4c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.83G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8f4ca98c54438fa1ad1ac1e61d3f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6dcc6f23f547fd9707df02cd9a6376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4c979b9e534570a37c131d028523be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94cec334f5f4288a0866dcc07f6bca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467c35531aca4ffb9a1603ede0c559ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31adc2c7128c43a0875d7b93b0e057a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4522eff8e7024b058915c2595d572a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/572 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/granite-3.2-2b-instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:35.886781Z",
     "iopub.status.busy": "2025-07-20T08:48:35.886105Z",
     "iopub.status.idle": "2025-07-20T08:48:41.156306Z",
     "shell.execute_reply": "2025-07-20T08:48:41.155680Z",
     "shell.execute_reply.started": "2025-07-20T08:48:35.886751Z"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "b630cc80-ff95-45a2-cc0d-38666010d73b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8, \n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.2, \n",
    "    bias = \"none\",    \n",
    "    use_gradient_checkpointing = \"unsloth\", \n",
    "    random_state = 42,\n",
    "    use_rslora = True, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:48.357831Z",
     "iopub.status.busy": "2025-07-20T08:48:48.357206Z",
     "iopub.status.idle": "2025-07-20T08:48:48.362396Z",
     "shell.execute_reply": "2025-07-20T08:48:48.361852Z",
     "shell.execute_reply.started": "2025-07-20T08:48:48.357783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "<a name=\"Data\"></a>\n",
    "### Data Prep\n",
    "We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n",
    "\n",
    "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
    "\n",
    "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
    "\n",
    "If you want to use the `ChatML` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing).\n",
    "\n",
    "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:48.661377Z",
     "iopub.status.busy": "2025-07-20T08:48:48.661206Z",
     "iopub.status.idle": "2025-07-20T08:48:48.670148Z",
     "shell.execute_reply": "2025-07-20T08:48:48.669443Z",
     "shell.execute_reply.started": "2025-07-20T08:48:48.661364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_ = df[['cleaned_transcript','description']].dropna()\n",
    "df_train, df_val = train_test_split(df_, test_size = 0.2, random_state = 42)\n",
    "df_val, df_test = train_test_split(df_val, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:50.795967Z",
     "iopub.status.busy": "2025-07-20T08:48:50.795657Z",
     "iopub.status.idle": "2025-07-20T08:48:50.816495Z",
     "shell.execute_reply": "2025-07-20T08:48:50.815786Z",
     "shell.execute_reply.started": "2025-07-20T08:48:50.795936Z"
    },
    "id": "LjY75GoYUCB8",
    "outputId": "9f40f734-788c-4793-c1af-e9d003337612",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prompt Formatting function using your Alpaca-style instruction\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func_row(row):\n",
    "    instruction = f\"\"\"\n",
    "            You are given words combination extracted from medical transcription and your task is determine the description \\n\n",
    "        \"\"\" \n",
    "    input_text = f\"Transcription: {row['cleaned_transcript']}\\nDescription:\"\n",
    "    prompt = instruction + input_text\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": row[\"description\"] + tokenizer.eos_token  # optional for causal LM\n",
    "    }\n",
    "\n",
    "\n",
    "# âœ… Apply formatting to all splits\n",
    "df_train_dicts = df_train.apply(formatting_prompts_func_row, axis=1).tolist()\n",
    "df_val_dicts   = df_val.apply(formatting_prompts_func_row, axis=1).tolist()\n",
    "df_test_dicts  = df_test.apply(formatting_prompts_func_row, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:52.402052Z",
     "iopub.status.busy": "2025-07-20T08:48:52.401386Z",
     "iopub.status.idle": "2025-07-20T08:48:52.428513Z",
     "shell.execute_reply": "2025-07-20T08:48:52.427983Z",
     "shell.execute_reply.started": "2025-07-20T08:48:52.402027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = Dataset.from_list(df_train_dicts)\n",
    "df_val   = Dataset.from_list(df_val_dicts)\n",
    "df_test  = Dataset.from_list(df_test_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:52.606694Z",
     "iopub.status.busy": "2025-07-20T08:48:52.606239Z",
     "iopub.status.idle": "2025-07-20T08:48:52.610918Z",
     "shell.execute_reply": "2025-07-20T08:48:52.610251Z",
     "shell.execute_reply.started": "2025-07-20T08:48:52.606676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:48:52.912177Z",
     "iopub.status.busy": "2025-07-20T08:48:52.911730Z",
     "iopub.status.idle": "2025-07-20T08:48:54.118738Z",
     "shell.execute_reply": "2025-07-20T08:48:54.117991Z",
     "shell.execute_reply.started": "2025-07-20T08:48:52.912158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470a5855da6245b487feac6ca080fbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1246 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89e759cd5d349a2afc1e14273d60e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e522d7eb5944d1785b291641044dd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/156 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "MAX_LENGTH = tokenizer.model_max_length  # usually 4096 or 8192 for Granite\n",
    "\n",
    "def tokenize_function(example):\n",
    "    # Tokenize prompt\n",
    "    prompt = tokenizer(\n",
    "        example[\"prompt\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "    # Tokenize response\n",
    "    response = tokenizer(\n",
    "        example[\"response\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        add_special_tokens=False,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "    # Add EOS token to response\n",
    "    response[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "    response[\"attention_mask\"].append(1)\n",
    "\n",
    "    # Combine\n",
    "    input_ids = prompt[\"input_ids\"] + response[\"input_ids\"]\n",
    "    attention_mask = prompt[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "    labels = [IGNORE_INDEX] * len(prompt[\"input_ids\"]) + response[\"input_ids\"]\n",
    "\n",
    "    # Truncate everything to model max length\n",
    "    input_ids = input_ids[:MAX_LENGTH]\n",
    "    attention_mask = attention_mask[:MAX_LENGTH]\n",
    "    labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "df_train = df_train.map(tokenize_function, remove_columns=df_train.column_names)\n",
    "df_val   = df_val.map(tokenize_function, remove_columns=df_val.column_names)\n",
    "df_test  = df_test.map(tokenize_function, remove_columns=df_test.column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T08:49:14.450258Z",
     "iopub.status.busy": "2025-07-20T08:49:14.449506Z",
     "iopub.status.idle": "2025-07-20T08:49:14.654681Z",
     "shell.execute_reply": "2025-07-20T08:49:14.654128Z",
     "shell.execute_reply.started": "2025-07-20T08:49:14.450230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                   = \"outputs/granite-3.3-summarization-v2\",\n",
    "    per_device_train_batch_size  = 1,  # Reduced for better gradient quality\n",
    "    gradient_accumulation_steps  = 16, # Increased to maintain effective batch size\n",
    "    learning_rate                = 1e-5, # Reduced for more stable convergence\n",
    "    warmup_ratio                 = 0.05, # Reduced warmup for smaller dataset\n",
    "    lr_scheduler_type            = \"cosine\",\n",
    "    max_steps                    = 150,  # Increased for better convergence\n",
    "    weight_decay                 = 0.01, # Reduced to prevent over-regularization\n",
    "    fp16                         = not is_bfloat16_supported(),\n",
    "    bf16                         = is_bfloat16_supported(),\n",
    "    logging_steps                = 10,   # Less frequent logging\n",
    "    save_total_limit             = 2,    # Reduced to save disk space\n",
    "    save_steps                   = 10,  # Save checkpoints periodically\n",
    "    eval_strategy                = \"steps\",\n",
    "    eval_steps                   = 10,  # Evaluate every 200 steps\n",
    "    load_best_model_at_end       = True,\n",
    "    metric_for_best_model        = \"eval_loss\",\n",
    "    greater_is_better            = False,\n",
    "    remove_unused_columns        = False,\n",
    "    seed                         = 3407,\n",
    "    report_to                    = \"none\",\n",
    "    dataloader_num_workers       = 2,    # Improved data loading\n",
    "    gradient_checkpointing       = True, # Memory optimization\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    label_pad_token_id=IGNORE_INDEX,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=df_train,\n",
    "    eval_dataset=df_test,\n",
    "    train_on_responses_only = False,\n",
    "    formatting_func=None,\n",
    "    dataset_text_field=None,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-07-20T08:49:14.691422Z",
     "iopub.status.busy": "2025-07-20T08:49:14.690808Z",
     "iopub.status.idle": "2025-07-20T08:49:14.696177Z",
     "shell.execute_reply": "2025-07-20T08:49:14.695443Z",
     "shell.execute_reply.started": "2025-07-20T08:49:14.691401Z"
    },
    "id": "2ejIt2xSNKKp",
    "outputId": "4815a050-0c0f-4a6a-9d93-b01c44eaea35",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.741 GB.\n",
      "2.686 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-20T08:49:16.184646Z",
     "iopub.status.busy": "2025-07-20T08:49:16.184424Z",
     "iopub.status.idle": "2025-07-20T09:26:04.845701Z",
     "shell.execute_reply": "2025-07-20T09:26:04.844857Z",
     "shell.execute_reply.started": "2025-07-20T08:49:16.184630Z"
    },
    "id": "yqxqAZ7KJ4oL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3cf26aac-6042-4458-c4a6-d8849efb6a95",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,246 | Num Epochs = 4 | Total steps = 150\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 16 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 14,090,240 of 2,000,000,000 (0.70% trained)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 35:46, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.233500</td>\n",
       "      <td>2.560643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.126500</td>\n",
       "      <td>2.189739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.903900</td>\n",
       "      <td>1.887745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.744600</td>\n",
       "      <td>1.693782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.465800</td>\n",
       "      <td>1.668347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.528300</td>\n",
       "      <td>1.646704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.882900</td>\n",
       "      <td>1.636334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.573500</td>\n",
       "      <td>1.632847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.469500</td>\n",
       "      <td>1.631538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.250600</td>\n",
       "      <td>1.630796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.056600</td>\n",
       "      <td>1.630439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.806900</td>\n",
       "      <td>1.630215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.372400</td>\n",
       "      <td>1.630041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.952900</td>\n",
       "      <td>1.630064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.022900</td>\n",
       "      <td>1.629989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Unsloth: Not an error, but GraniteForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T09:26:25.719986Z",
     "iopub.status.busy": "2025-07-20T09:26:25.719274Z",
     "iopub.status.idle": "2025-07-20T09:26:26.090241Z",
     "shell.execute_reply": "2025-07-20T09:26:26.089677Z",
     "shell.execute_reply.started": "2025-07-20T09:26:25.719952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('finetuned-IBM-Granite/tokenizer_config.json',\n",
       " 'finetuned-IBM-Granite/special_tokens_map.json',\n",
       " 'finetuned-IBM-Granite/chat_template.jinja',\n",
       " 'finetuned-IBM-Granite/vocab.json',\n",
       " 'finetuned-IBM-Granite/merges.txt',\n",
       " 'finetuned-IBM-Granite/added_tokens.json',\n",
       " 'finetuned-IBM-Granite/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"finetuned-IBM-Granite\")\n",
    "tokenizer.save_pretrained(\"finetuned-IBM-Granite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T09:27:16.276178Z",
     "iopub.status.busy": "2025-07-20T09:27:16.275408Z",
     "iopub.status.idle": "2025-07-20T09:27:24.132204Z",
     "shell.execute_reply": "2025-07-20T09:27:24.131370Z",
     "shell.execute_reply.started": "2025-07-20T09:27:16.276144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Granite patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Load your fine-tuned model back (just in case you're in new runtime)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    \"finetuned-IBM-Granite\",\n",
    "    dtype=None,\n",
    "    load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-20T09:40:00.512012Z",
     "iopub.status.busy": "2025-07-20T09:40:00.511432Z",
     "iopub.status.idle": "2025-07-20T10:24:30.940395Z",
     "shell.execute_reply": "2025-07-20T10:24:30.939694Z",
     "shell.execute_reply.started": "2025-07-20T09:40:00.511985Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  1%|          | 1/156 [00:17<44:44, 17.32s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  1%|â–         | 2/156 [00:34<44:29, 17.33s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  2%|â–         | 3/156 [00:51<44:07, 17.31s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  3%|â–Ž         | 4/156 [01:09<43:49, 17.30s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  3%|â–Ž         | 5/156 [01:26<43:34, 17.31s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  4%|â–         | 6/156 [01:43<43:09, 17.26s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  4%|â–         | 7/156 [02:00<42:41, 17.19s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  5%|â–Œ         | 8/156 [02:17<42:24, 17.19s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  6%|â–Œ         | 9/156 [02:35<42:02, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  6%|â–‹         | 10/156 [02:52<41:50, 17.19s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  7%|â–‹         | 11/156 [03:09<41:34, 17.20s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  8%|â–Š         | 12/156 [03:26<41:20, 17.22s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  8%|â–Š         | 13/156 [03:43<41:00, 17.21s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "  9%|â–‰         | 14/156 [04:01<40:40, 17.19s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 10%|â–‰         | 15/156 [04:18<40:18, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 10%|â–ˆ         | 16/156 [04:35<40:02, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 11%|â–ˆ         | 17/156 [04:52<39:46, 17.17s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 12%|â–ˆâ–        | 18/156 [05:09<39:24, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 12%|â–ˆâ–        | 19/156 [05:26<39:04, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 13%|â–ˆâ–Ž        | 20/156 [05:43<38:50, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 13%|â–ˆâ–Ž        | 21/156 [06:01<38:33, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 14%|â–ˆâ–        | 22/156 [06:18<38:13, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 15%|â–ˆâ–        | 23/156 [06:35<37:57, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 15%|â–ˆâ–Œ        | 24/156 [06:52<37:39, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 16%|â–ˆâ–Œ        | 25/156 [07:09<37:26, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 17%|â–ˆâ–‹        | 26/156 [07:26<37:09, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 17%|â–ˆâ–‹        | 27/156 [07:43<36:56, 17.19s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 18%|â–ˆâ–Š        | 28/156 [08:01<36:40, 17.19s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 19%|â–ˆâ–Š        | 29/156 [08:18<36:26, 17.22s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 19%|â–ˆâ–‰        | 30/156 [08:35<36:14, 17.26s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 20%|â–ˆâ–‰        | 31/156 [08:52<35:44, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 21%|â–ˆâ–ˆ        | 32/156 [09:09<35:26, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 21%|â–ˆâ–ˆ        | 33/156 [09:26<35:02, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 22%|â–ˆâ–ˆâ–       | 34/156 [09:43<34:45, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 22%|â–ˆâ–ˆâ–       | 35/156 [10:01<34:28, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 36/156 [10:18<34:13, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 24%|â–ˆâ–ˆâ–Ž       | 37/156 [10:35<33:51, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 24%|â–ˆâ–ˆâ–       | 38/156 [10:52<33:37, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 39/156 [11:09<33:24, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 40/156 [11:26<33:06, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 26%|â–ˆâ–ˆâ–‹       | 41/156 [11:43<32:49, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 27%|â–ˆâ–ˆâ–‹       | 42/156 [12:00<32:29, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 28%|â–ˆâ–ˆâ–Š       | 43/156 [12:17<32:15, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 28%|â–ˆâ–ˆâ–Š       | 44/156 [12:35<31:58, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 29%|â–ˆâ–ˆâ–‰       | 45/156 [12:52<31:41, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 29%|â–ˆâ–ˆâ–‰       | 46/156 [13:09<31:22, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 47/156 [13:26<31:07, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 48/156 [13:43<30:53, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 49/156 [14:00<30:35, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 50/156 [14:18<30:19, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 51/156 [14:35<30:01, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 52/156 [14:52<29:44, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 53/156 [15:09<29:25, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 54/156 [15:26<29:09, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 55/156 [15:43<28:50, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 56/156 [16:00<28:32, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 57/156 [16:17<28:12, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 58/156 [16:35<27:59, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 59/156 [16:52<27:42, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 60/156 [17:09<27:27, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 61/156 [17:26<27:11, 17.17s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 62/156 [17:43<26:51, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 63/156 [18:00<26:30, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 64/156 [18:17<26:18, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 65/156 [18:35<26:01, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/156 [18:52<25:44, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 67/156 [19:09<25:26, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 68/156 [19:26<25:06, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 69/156 [19:43<24:48, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 70/156 [20:00<24:28, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 71/156 [20:17<24:12, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 72/156 [20:34<23:56, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 73/156 [20:51<23:38, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 74/156 [21:08<23:20, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 75/156 [21:25<23:00, 17.05s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 76/156 [21:43<22:44, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 77/156 [22:00<22:29, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 78/156 [22:17<22:13, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 79/156 [22:34<21:56, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 80/156 [22:51<21:41, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/156 [23:08<21:25, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 82/156 [23:25<21:07, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 83/156 [23:42<20:50, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 84/156 [23:59<20:29, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 85/156 [24:17<20:16, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 86/156 [24:34<19:57, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 87/156 [24:51<19:38, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 88/156 [25:08<19:21, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 89/156 [25:25<19:04, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 90/156 [25:42<18:47, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 91/156 [25:59<18:32, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 92/156 [26:16<18:16, 17.14s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 93/156 [26:33<17:57, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 94/156 [26:50<17:39, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 95/156 [27:08<17:21, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 96/156 [27:25<17:06, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/156 [27:42<16:48, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 98/156 [27:59<16:30, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 99/156 [28:16<16:12, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 100/156 [28:33<15:56, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 101/156 [28:50<15:40, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 102/156 [29:07<15:26, 17.15s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 103/156 [29:25<15:09, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 104/156 [29:42<14:52, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 105/156 [29:59<14:35, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 106/156 [30:16<14:18, 17.16s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 107/156 [30:33<14:01, 17.17s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 108/156 [30:50<13:41, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 109/156 [31:07<13:24, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 110/156 [31:24<13:07, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 111/156 [31:42<12:50, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/156 [31:59<12:32, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 113/156 [32:16<12:16, 17.13s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 114/156 [32:33<11:58, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 115/156 [32:50<11:41, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 116/156 [33:07<11:24, 17.10s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 117/156 [33:24<11:07, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 118/156 [33:41<10:50, 17.11s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 119/156 [33:58<10:31, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 120/156 [34:15<10:15, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 121/156 [34:33<09:59, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 122/156 [34:50<09:41, 17.12s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 123/156 [35:07<09:23, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 124/156 [35:24<09:06, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 125/156 [35:41<08:49, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 126/156 [35:58<08:32, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 127/156 [36:15<08:15, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 128/156 [36:32<07:57, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 129/156 [36:49<07:41, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 130/156 [37:06<07:22, 17.02s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 131/156 [37:23<07:05, 17.03s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 132/156 [37:40<06:49, 17.04s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 133/156 [37:57<06:32, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 134/156 [38:14<06:16, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 135/156 [38:31<05:58, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 136/156 [38:48<05:41, 17.05s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 137/156 [39:06<05:24, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 138/156 [39:23<05:07, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 139/156 [39:40<04:50, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 140/156 [39:57<04:32, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 141/156 [40:14<04:15, 17.04s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 142/156 [40:31<03:58, 17.05s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 143/156 [40:48<03:41, 17.03s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 144/156 [41:05<03:24, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 145/156 [41:22<03:07, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 146/156 [41:39<02:50, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 147/156 [41:56<02:33, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 148/156 [42:13<02:16, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 149/156 [42:30<01:59, 17.06s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 150/156 [42:47<01:42, 17.04s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 151/156 [43:04<01:25, 17.07s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 152/156 [43:22<01:08, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 153/156 [43:39<00:51, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 154/156 [43:56<00:34, 17.08s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 155/156 [44:13<00:17, 17.09s/it]You've set `assistant_model`, which triggers assisted generate. Currently, assisted generate is only supported with Greedy Search and Sample. However, the base decoding mode (based on current flags) is GenerationMode.BEAM_SEARCH -- some of the set flags will be ignored.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [44:30<00:00, 17.12s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for batch in tqdm(df_test):\n",
    "    # Convert each field to a tensor\n",
    "    input_ids = torch.tensor(batch[\"input_ids\"]).unsqueeze(0).to(device)          # [1, seq_len]\n",
    "    attention_mask = torch.tensor(batch[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "    labels = torch.tensor(batch[\"labels\"]).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=128,\n",
    "            num_beams=4,\n",
    "            do_sample=False,\n",
    "        )\n",
    "    \n",
    "    # Trim input from generated\n",
    "    input_length = input_ids.shape[1]\n",
    "    generated_ids = generated_ids[:, input_length:]\n",
    "    \n",
    "    # Decode\n",
    "    decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "    decoded_refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    predictions.extend(decoded_preds)\n",
    "    references.extend(decoded_refs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T10:25:11.268929Z",
     "iopub.status.busy": "2025-07-20T10:25:11.268562Z",
     "iopub.status.idle": "2025-07-20T10:25:16.831167Z",
     "shell.execute_reply": "2025-07-20T10:25:16.830269Z",
     "shell.execute_reply.started": "2025-07-20T10:25:11.268889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore:\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BERTScore\n",
    "bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T10:25:47.322640Z",
     "iopub.status.busy": "2025-07-20T10:25:47.322354Z",
     "iopub.status.idle": "2025-07-20T10:25:47.327370Z",
     "shell.execute_reply": "2025-07-20T10:25:47.326685Z",
     "shell.execute_reply.started": "2025-07-20T10:25:47.322619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore:\n",
      "precision : 0.7450296359184461\n",
      "recall : 0.8166497269502053\n",
      "f1 : 0.7782353988060584\n"
     ]
    }
   ],
   "source": [
    "print(\"BERTScore:\")\n",
    "\n",
    "for score in bertscore_result  : \n",
    "    if score != 'hashcode':\n",
    "        result = np.array(bertscore_result[score]).mean()\n",
    "        print(f'{score} : {result}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 64826,
     "sourceId": 127612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
